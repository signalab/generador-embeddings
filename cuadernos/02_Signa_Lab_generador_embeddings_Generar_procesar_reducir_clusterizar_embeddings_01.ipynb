{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFHaGxXuNcOT"
      },
      "source": [
        "# **Signa_Lab ITESO:** Generador de *Embbeddings*\n",
        "\n",
        "## **Cuaderno 02:** Generación de *embeddings*, reducción de dimensionalidades y clusterización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0UWcYzNjsq"
      },
      "source": [
        "Cuaderno de código para generar *embeddings* (relaciones semánticas codificadas en vectores) a partir de datos textuales, idealmente, procesados y depurados con antelación ([ver cuaderno 01](https://github.com/signalab/generador-embeddings/blob/main/cuadernos/01_Signa_Lab_generador_embeddings_Depuraci%C3%B3n_importar_limpiar_depurar_texto_01.ipynb)), con ayuda de modelos de lenguaje de la librería [sentence-transformers](https://www.sbert.net/), alojados en repositorios de [HuggingFace](https://huggingface.co/sentence-transformers) (en la nube) o descargados localmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EHlbspzMJyO"
      },
      "source": [
        "## 1. Importar librerías, dependencias y archivo de datos a para la generación de *embeddings*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23B1fl0tWOI"
      },
      "source": [
        "**Instalar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXLwyzU7vuH"
      },
      "outputs": [],
      "source": [
        "# Instalar librerías de Python necesarias\n",
        "!pip install nbformat\n",
        "!pip install tf-keras\n",
        "!pip install tensorflow_text\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install numpy\n",
        "!pip install operator\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "!pip install nltk\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install plotly\n",
        "!pip install umap-learn\n",
        "!pip install yellowbrick\n",
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1KawEEvNsWa"
      },
      "source": [
        "**Importar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlVhFJrFNtlt"
      },
      "outputs": [],
      "source": [
        "# Importar librerías de Python necesarias\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "import nltk\n",
        "\n",
        "from sklearn import datasets\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "import ipywidgets as widgets\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k6IZmxNNk13m"
      },
      "outputs": [],
      "source": [
        "# Definir función para implementar barra de progreso sobre el procesamiento\n",
        "def with_progress_bar(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Inicia el contador de tiempo\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Crea una barra de progreso\n",
        "        pbar = tqdm(total=100, desc=\"Processing\", ncols=70)\n",
        "\n",
        "        # Define una función interna para actualizar la barra de progreso\n",
        "        def update_progress_bar(i):\n",
        "            pbar.update(i)\n",
        "\n",
        "        # Agrega la función de actualización al diccionario de argumentos\n",
        "        kwargs['update_progress_bar'] = update_progress_bar\n",
        "\n",
        "        # Ejecuta la función original\n",
        "        result = func(*args, **kwargs)\n",
        "\n",
        "        # Finaliza la barra de progreso\n",
        "        pbar.close()\n",
        "\n",
        "        # Calcula y muestra el tiempo de ejecución\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
        "\n",
        "        return result\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cargar archivos con los que se trabajará"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir función para cargar archivos a partir de la extensión en su ruta indicada\n",
        "def load_file(path, encoding='utf-8'):\n",
        "    if path.endswith('.csv'):\n",
        "        return pd.read_csv(path, encoding=encoding)\n",
        "    elif path.endswith('.xlsx'):\n",
        "        return pd.read_excel(path)\n",
        "    else:\n",
        "        raise ValueError(\"Formato no compatible. Por favor carga solo archivos .csv or .xlsx.\")\n",
        "\n",
        "# Inicializar lista para alojar todas las rutas y una variable para el DataFrame final, accesible globalmente\n",
        "file_paths = []\n",
        "dfs = []\n",
        "df = None  # DataFrame global\n",
        "\n",
        "# Lista de codificaciones comunes\n",
        "encoding_options = ['utf-8', 'latin1', 'ISO-8859-1']\n",
        "\n",
        "# Dropdown para seleccionar la codificación del archivo\n",
        "encoding_dropdown = widgets.Dropdown(\n",
        "    options=encoding_options,\n",
        "    value='utf-8',\n",
        "    description='Codificación:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Campo de texto (input) para indicar nombre del proyecto (para integrarse en nombres de archivos a exportar)\n",
        "project_name = widgets.Text(value='', placeholder='Escribe el nombre del proyecto (corto y sin espacios)', description='Nombre del proyecto:')\n",
        "\n",
        "# Botones para añadir y eliminar archivos\n",
        "add_button = widgets.Button(description=\"Añadir archivo\")\n",
        "remove_button = widgets.Button(description=\"Eliminar archivo\")\n",
        "load_button = widgets.Button(description=\"Cargar archivos\")\n",
        "\n",
        "# Lista para almacenar los widgets de rutas de archivos\n",
        "file_paths_widgets = []\n",
        "\n",
        "# Función para añadir un campo de texto para la ruta del archivo\n",
        "def add_file_input(b=None):\n",
        "    file_path = widgets.Text(value='', placeholder='Escribe la ruta del archivo', description='Ruta del archivo:')\n",
        "    file_paths_widgets.append(file_path)\n",
        "    update_ui()\n",
        "\n",
        "# Función para eliminar el último campo de texto de la ruta del archivo\n",
        "def remove_file_input(b=None):\n",
        "    if file_paths_widgets:\n",
        "        file_paths_widgets.pop()\n",
        "    update_ui()\n",
        "\n",
        "# Función para procesar los archivos\n",
        "def process_files(b=None):\n",
        "    global df\n",
        "    dfs.clear()\n",
        "    for file_path in file_paths_widgets:\n",
        "        path = file_path.value\n",
        "        try:\n",
        "            temp_df = load_file(path, encoding=encoding_dropdown.value)\n",
        "            dfs.append(temp_df)\n",
        "            print(f\"Nombre de archivo: {path}\")\n",
        "            print(f\"Filas/Columnas (shape): {temp_df.shape}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error al cargar el archivo {path}: {e}\")\n",
        "            return\n",
        "\n",
        "    if dfs:\n",
        "        df = pd.concat(dfs, ignore_index=True)  # Concatenate all DataFrames\n",
        "        print(\"\\n¡Se cargaron todos los archivos!\")\n",
        "        print(f\"Filas/Columnas (shape) de DataFrame creado: {df.shape}\")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para actualizar las opciones del dropdown de columnas\n",
        "def update_column_options():\n",
        "    if df is not None:\n",
        "        column_dropdown.options = df.columns.tolist()\n",
        "\n",
        "# Definir función para actualizar UI\n",
        "def update_ui():\n",
        "    clear_output()\n",
        "    display(project_name)\n",
        "    display(encoding_dropdown)\n",
        "    for path_input in file_paths_widgets:\n",
        "        display(path_input)\n",
        "    display(widgets.HBox([add_button, remove_button]))\n",
        "    display(load_button)\n",
        "    display(output)\n",
        "\n",
        "# Inicializar UI con un campo de texto (input) para ruta de archivo\n",
        "add_file_input()\n",
        "\n",
        "# Conectar botones a funciones\n",
        "add_button.on_click(add_file_input)\n",
        "remove_button.on_click(remove_file_input)\n",
        "load_button.on_click(process_files)\n",
        "\n",
        "# Mostrar la UI inicial\n",
        "update_ui()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dgB2fTZk13n"
      },
      "source": [
        "**Cargar modelo de lenguaje** para su implementación en librería de *sentence-transformers*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv-AoqmSpMCG"
      },
      "outputs": [],
      "source": [
        "embedder = None\n",
        "\n",
        "pre_tested_models = [\n",
        "    \"intfloat/multilingual-e5-large-instruct\",\n",
        "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "]\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=pre_tested_models + [\"other or local\"],\n",
        "    value=pre_tested_models[0],\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "custom_model_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter custom model path',\n",
        "    description='Custom Path:',\n",
        "    disabled=True\n",
        ")\n",
        "\n",
        "confirm_button = widgets.Button(\n",
        "    description='Aceptar',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_model_change(change):\n",
        "    if change['new'] == \"other or local\":\n",
        "        custom_model_input.disabled = False\n",
        "    else:\n",
        "        custom_model_input.disabled = True\n",
        "\n",
        "model_dropdown.observe(on_model_change, names='value')\n",
        "\n",
        "def load_model(b):\n",
        "    global embedder\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        model_path = model_dropdown.value\n",
        "        if model_path == \"other or local\":\n",
        "            model_path = custom_model_input.value\n",
        "        embedder = SentenceTransformer(model_path)\n",
        "        print(f\"Model loaded from: {model_path}\")\n",
        "\n",
        "confirm_button.on_click(load_model)\n",
        "\n",
        "display(model_dropdown, custom_model_input, confirm_button, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m32UcQATOp3"
      },
      "outputs": [],
      "source": [
        "print(embedder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Pi3v0fweWi"
      },
      "source": [
        "**Para un solo archivo**, revisar registros importados desde archivo individual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK3TER2kT6Zw"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de datos importados de archivo individual\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rT7qqnH_hm0Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(179, 5)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verificar número de filas y columnas en datos importados de archivo individual\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KybuZl2SEry"
      },
      "source": [
        "## 2. Generar *embeddings* con el modelo de lenguaje cargado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqapTyPNpWcm"
      },
      "source": [
        "**Definir función para generar embeddings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "luMVyv37OCNP"
      },
      "outputs": [],
      "source": [
        "# Definir función para generar embeddings\n",
        "@with_progress_bar\n",
        "def generate(mod, dfl, colText, update_progress_bar=None):\n",
        "    tot = len(dfl)\n",
        "    dfW = dfl\n",
        "    dfW.loc[:, \"Embedding\"] = None\n",
        "    for index, row in dfW.iterrows():\n",
        "        # Iterar sobre el DataFrame y codificar cada texto\n",
        "        embedding = mod.encode(str(row[colText])).tolist()\n",
        "        dfW.at[index, 'Embedding'] = embedding\n",
        "        # Actualizar la barra de progreso una vez por cada 10 filas\n",
        "        if update_progress_bar is not None:\n",
        "            update_progress_bar((index/tot)*2)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj8CklhMSOZp"
      },
      "source": [
        "**Para un solo archivo**, generar embeddings con archivo de datos cargado en data frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0AlZb1MSJnc"
      },
      "outputs": [],
      "source": [
        "# Dropdown para seleccionar la columna del DataFrame\n",
        "column_dropdown = widgets.Dropdown(\n",
        "    options=df.columns.tolist(),\n",
        "    description='Columna:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y generar los embeddings\n",
        "generate_button = widgets.Button(\n",
        "    description='Generar Embeddings',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para generar los embeddings\n",
        "def generate_embeddings(b):\n",
        "    global datasetEmbeddings\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        textCol = column_dropdown.value\n",
        "        # Asegúrate de que embedder esté definido globalmente\n",
        "        datasetEmbeddings = generate(embedder, df, textCol)\n",
        "        print(f\"Embeddings generados para la columna: {textCol}\")\n",
        "\n",
        "generate_button.on_click(generate_embeddings)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(column_dropdown, generate_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-fP-hdfUCdx"
      },
      "source": [
        "**Exportar archivos de datos con embeddings generados (en formato CSV):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXGIRV0oUaR9"
      },
      "outputs": [],
      "source": [
        "# Input de texto para el nombre del archivo\n",
        "file_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe el nombre del archivo',\n",
        "    description='Nombre Archivo:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para exportar el archivo\n",
        "export_button = widgets.Button(\n",
        "    description='Exportar CSV',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para exportar el archivo CSV\n",
        "def export_csv(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        nombreArchivo = file_name_input.value\n",
        "        datasetEmbeddings.to_csv(f\"{nombreArchivo}Embeddings.csv\")\n",
        "        print(f\"{nombreArchivo}Embeddings descargado en csv\")\n",
        "\n",
        "export_button.on_click(export_csv)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(file_name_input, export_button, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasetEmbeddings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVoYsHAu7Vu4"
      },
      "source": [
        "## **3. Reducción de dimensiones con distintas técnicas (UMAP, PCA, TSNE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wd1bJ2I78ja"
      },
      "source": [
        "**Elegir data frame** con embeddings para reducir dimensionalidaes y clusterizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7jkjqVrj8QIa"
      },
      "outputs": [],
      "source": [
        "# Elegir data frame con embeddings (df, en caso de un solo archivo, df1,2,3... e caso de múltiples archivos:\n",
        "\n",
        "# Un solo archivo cargado con embeddings generados\n",
        "dfClusters = datasetEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcYVTm_7a-y"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **UMAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xppikbye7dVy"
      },
      "outputs": [],
      "source": [
        "# Definir función para UMAP\n",
        "def genUMAP(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    umap_model = umap.UMAP(n_components=nDims)\n",
        "    X_umap = umap_model.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = X_umap.tolist()\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pInnYTLHbQNu"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d7MnIWmVbPo_"
      },
      "outputs": [],
      "source": [
        "# Definir función para PCA\n",
        "def genPCA(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    pca = PCA(n_components=nDims)\n",
        "    X_pca = pca.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_pca)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCzptnIbV46"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **TSNE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tPrc8VxubYG7"
      },
      "outputs": [],
      "source": [
        "# Definir función para TSNE\n",
        "def genTSNE(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    tsne = TSNE(n_components=nDims, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_tsne)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPasLSMzfsuO"
      },
      "source": [
        "**Definir función para elegir método para reducir dimensiones:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZIBL8r8yfwJW"
      },
      "outputs": [],
      "source": [
        "def reduceDim(df, columnaEmbeddings, nDims, method):\n",
        "    if method.lower() == 'umap':\n",
        "        return genUMAP(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'pca':\n",
        "        return genPCA(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'tsne':\n",
        "        return genTSNE(df, columnaEmbeddings, nDims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3nKQlzIWNY"
      },
      "source": [
        "**Elegir método a utilizar, número de dimensiones (2D o 3D) y ejecutar reducción de dimensionalidades sobre *embeddings* cargados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLxWPxkAfglA"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings completos (vector dado por las dimensiones del modelo de lenguaje)\n",
        "columnaConEmbeddings = \"Embedding\"\n",
        "\n",
        "# Indicar si se busca reducir a 2 o 3 dimensiones para visualizador 2D o 3D\n",
        "numDimensiones = 3\n",
        "\n",
        "# Dropdown para elegir el método de reducción de dimensionalidades\n",
        "metodo_dropdown = widgets.Dropdown(\n",
        "    options=[\"umap\", \"pca\", \"tsne\"],\n",
        "    value=\"umap\",\n",
        "    description='Método:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y ejecutar la reducción de dimensionalidades\n",
        "reduce_button = widgets.Button(\n",
        "    description='Reducir Dimensiones',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para ejecutar la reducción de dimensionalidades\n",
        "def reducir_dimensiones(b):\n",
        "    global datasetConDimensionesReducidas\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        metodo = metodo_dropdown.value\n",
        "        datasetConDimensionesReducidas = reduceDim(dfClusters, columnaConEmbeddings, numDimensiones, metodo)\n",
        "        print(f\"Reducción de dimensionalidades completada usando el método: {metodo}\")\n",
        "\n",
        "reduce_button.on_click(reducir_dimensiones)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(metodo_dropdown, reduce_button, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFtGIdSqbEOZ"
      },
      "outputs": [],
      "source": [
        "datasetConDimensionesReducidas.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RTG4Qt9ccBu"
      },
      "source": [
        "## **4. Clusterización y visualización de *embeddings***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfTwsNNWcecc"
      },
      "source": [
        "Definir función para **Método del Codo** para calcular número ideal de clústers para los datos cargados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KMmtd5NFcdqh"
      },
      "outputs": [],
      "source": [
        "def elbowMethod(df, columnWiEmbeddings, rangoPosibleDeCluster, byRegion=False):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWiEmbeddings].tolist())\n",
        "    # Calcula la inercia para diferentes valores de k (número de clústeres)\n",
        "    # Inicializa una lista vacía para almacenar los valores de inercia calculados para cada número de clústeres\n",
        "    inertia_values = []\n",
        "    # Define un rango de valores de k (número de clústeres) para probar, basándose en el rango proporcionado como argumento\n",
        "    possible_k_values = range(rangoPosibleDeCluster[0], rangoPosibleDeCluster[1]+1)  # Prueba k desde n1 hasta n2 clústeres\n",
        "\n",
        "    # Itera sobre el rango de posibles valores de k\n",
        "    for index, k in enumerate(possible_k_values):\n",
        "        # Inicializa el algoritmo KMeans con el número actual de clústeres (k) y una semilla aleatoria fija\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "        # Entrena el modelo KMeans con los embeddings\n",
        "        kmeans.fit(embeddings)\n",
        "\n",
        "        # Añade la inercia del modelo (la suma de las distancias cuadradas de las muestras a su centro de clúster más cercano) a la lista de valores de inercia\n",
        "        inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "    # Prepara los resultados para ser graficados, conteniendo los valores de k y las inercias correspondientes\n",
        "    resToPlot = [possible_k_values, inertia_values]\n",
        "\n",
        "    # Grafica el método del codo utilizando matplotlib, donde el eje X representa el número de clústeres y el eje Y la inercia\n",
        "    plt.plot(resToPlot[0], resToPlot[1], marker='o')\n",
        "    plt.xlabel('Número de Clústeres (k)')\n",
        "    plt.ylabel('Inercia')\n",
        "    plt.title('Método del Codo para Determinar k')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng9IUzHlguCH"
      },
      "source": [
        "**Ejecutar método del codo** para identificar número deseable de clústers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0pCw4dSgxxh"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Calcular número ideal en un rango de 1 a 20 clústers\n",
        "rangoDeClusters = [1,20]\n",
        "elbowMethod(datasetConDimensionesReducidas, columnaConEmbeddings, rangoDeClusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgGoiC-85QEh"
      },
      "source": [
        "Definir función para **Método de Silueta** para calcular número ideal de clústers para los datos cargados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "coX058Qt5Pmm"
      },
      "outputs": [],
      "source": [
        "def silhouetteMethod(df, columnWithEmbeddings, rangeOfClusters):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWithEmbeddings].tolist())\n",
        "\n",
        "    # Establece el número de subplots basado en el rango de clústeres a analizar\n",
        "    n_clusters = range(rangeOfClusters[0], rangeOfClusters[1] + 1)\n",
        "    n_rows = len(n_clusters) // 2 + len(n_clusters) % 2\n",
        "    fig, ax = plt.subplots(n_rows, 2, figsize=(16, 32))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "    # Itera sobre el rango especificado de número de clústeres\n",
        "    for i, k in enumerate(n_clusters):\n",
        "        # Crea una instancia de KMeans para el número actual de clústeres\n",
        "        km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
        "\n",
        "        # Calcula la fila y columna para el subplot actual\n",
        "        q, mod = divmod(i, 2)\n",
        "\n",
        "        # Crea una instancia de SilhouetteVisualizer para visualizar el coeficiente de silueta\n",
        "        visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q][mod])\n",
        "\n",
        "        # Ajusta el visualizador con los embeddings\n",
        "        visualizer.fit(embeddings)\n",
        "\n",
        "        # Establece el título del subplot\n",
        "        ax[q][mod].set_title(f'Clusters: {k}')\n",
        "\n",
        "    # Ajusta la disposición de los subplots para evitar solapamientos\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUt22TJUKG1G"
      },
      "outputs": [],
      "source": [
        "# Ejecutar función de método de silueta\n",
        "silhouetteMethod(dfClusters, 'embeddingsReducidos', (2, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCgFS0ucg0n"
      },
      "source": [
        "Definir función de clusterizarización utilizando método **K-Means:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7m26wIKEciSI"
      },
      "outputs": [],
      "source": [
        "# Definir función de clusterización con K-means\n",
        "def clusterKmeans(df, optimal_k_value, columnaEmbeddings, byRegion=False, cluster_col_name=None):\n",
        "    embeddings = df[columnaEmbeddings].tolist()\n",
        "    dfW = df.copy() # Crear copia de trabajo de DataFrame\n",
        "\n",
        "    if cluster_col_name is None:\n",
        "      cluster_col_name = \"cluster\"\n",
        "\n",
        "    try:\n",
        "        if byRegion: # Clusterización por región (opcional, no utilizado en metodología final)\n",
        "            # Inicializar nueva columna para alojar etiquetas de clústeres\n",
        "            dfW[cluster_col_name] = None\n",
        "\n",
        "            # Iterar sobre cada región (opcional)\n",
        "            for region, df_region in dfW.groupby('region'):\n",
        "                # Aplicar clusterización de K-means en cada región (opcional)\n",
        "                kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "                cluster_labels = kmeans.fit_predict(df_region[columnaEmbeddings].tolist())\n",
        "\n",
        "                # Añadir prefijo de clúster por región (opcional)\n",
        "                prefixed_cluster_labels = [f\"{region}_{label}\" for label in cluster_labels]\n",
        "\n",
        "                # Asignar etiquetas de clúster por región a DataFrame\n",
        "                dfW.loc[dfW['region'] == region, cluster_col_name] = prefixed_cluster_labels\n",
        "        else:\n",
        "            # Aplicar clusterización por K-means a todo el conjunto de datos importado (versión implementada en metodología final)\n",
        "            kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "            cluster_labels = kmeans.fit_predict(embeddings)\n",
        "            dfW[cluster_col_name] = cluster_labels\n",
        "\n",
        "        return dfW\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar clusters: {e}\")\n",
        "        return pd.DataFrame({0: [\"Error al generar clusters\"]})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8e-qbFYhV3a"
      },
      "source": [
        "**Ejecutar clusterización** con número deseado de clúster con método *k-means:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYDZGoBShW-2"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "\n",
        "# Input para el número de clusters\n",
        "numero_clusters_input = widgets.IntText(\n",
        "    value=7,\n",
        "    description='Núm. Clusters:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y ejecutar la segmentación en clusters\n",
        "cluster_button = widgets.Button(\n",
        "    description='Segmentar Clusters',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para ejecutar la segmentación en clusters\n",
        "def segmentar_clusters(b):\n",
        "    global dfClusterizado\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        numeroDeClusters = numero_clusters_input.value\n",
        "        dfClusterizado = clusterKmeans(datasetConDimensionesReducidas, numeroDeClusters, columnaConEmbeddings, byRegion=False)\n",
        "        print(f\"Segmentación en {numeroDeClusters} clusters completada.\")\n",
        "\n",
        "cluster_button.on_click(segmentar_clusters)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(numero_clusters_input, cluster_button, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSnflYhvvupM"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de registros con sus respectivos clústers asignados\n",
        "dfClusterizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65amorfRec8J"
      },
      "source": [
        "Definir función para **visualizar relaciones semánticas y clústeres en 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "AvxpKaLbeltl"
      },
      "outputs": [],
      "source": [
        "def visualize3D(df, columnaEmbeddingsReducidas, columnaTexto, byRegion=False, columnaCluster=None):\n",
        "  if columnaCluster is None:\n",
        "    columnaCluster = \"cluster\"\n",
        "  embeddingWithSelectedDimensions = df[columnaEmbeddingsReducidas].tolist()\n",
        "  dfToPlot = {\n",
        "        \"X\": [x[0] for x in embeddingWithSelectedDimensions],\n",
        "        \"Y\": [y[1] for y in embeddingWithSelectedDimensions],\n",
        "        \"Z\": [z[2] for z in embeddingWithSelectedDimensions],\n",
        "        \"cluster\": df[columnaCluster].tolist(),\n",
        "        \"text\": df[columnaTexto]\n",
        "  }\n",
        "\n",
        "  fig = px.scatter_3d(dfToPlot, x='X', y='Y', z='Z', color='cluster', hover_data=[\"text\"],\n",
        "                         labels={'X': 'Dimensión 1', 'Y': 'Dimensión 2', 'Z': 'Dimensión 3'},\n",
        "                         title=f'Visualización de clústers semánticos',\n",
        "                         color_discrete_sequence=px.colors.sequential.Viridis)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97inR3riC6g"
      },
      "source": [
        "**Ejecutar visualización de clústers 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "\n",
        "# Dropdown para seleccionar la columna de texto para etiquetas\n",
        "columna_texto_dropdown = widgets.Dropdown(\n",
        "    options=dfClusterizado.columns.tolist(),\n",
        "    value=dfClusterizado.columns.tolist()[0],\n",
        "    description='Columna Texto:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y visualizar en 3D\n",
        "visualize_button = widgets.Button(\n",
        "    description='Visualizar 3D',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para visualizar en 3D\n",
        "def visualizar_3d():\n",
        "    columnaTextoClusterizado = columna_texto_dropdown.value\n",
        "    visualize3D(dfClusterizado, columnaConEmbeddings, columnaTextoClusterizado, columnaCluster=\"cluster\")\n",
        "    print(f\"Visualización 3D completada usando la columna de texto: {columnaTextoClusterizado}\")\n",
        "\n",
        "# Función para manejar el evento del botón\n",
        "def on_visualize_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        visualizar_3d()\n",
        "\n",
        "visualize_button.on_click(on_visualize_button_clicked)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(columna_texto_dropdown, visualize_button, output)\n",
        "\n",
        "# Ejecutar la visualización fuera del widget\n",
        "visualizar_3d()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_elu-UcSfhWH"
      },
      "source": [
        "**Exportar archivos de datos (formato CSV y JSON) con clústers calculados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et8wiYQFiXI1"
      },
      "outputs": [],
      "source": [
        "# Dropdown para seleccionar el formato de exportación\n",
        "format_dropdown = widgets.Dropdown(\n",
        "    options=['csv', 'json'],\n",
        "    value='csv',\n",
        "    description='Formato:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Input de texto para el nombre del archivo\n",
        "file_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe el nombre del archivo',\n",
        "    description='Nombre Archivo:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para exportar el archivo\n",
        "export_button = widgets.Button(\n",
        "    description='Exportar',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para exportar el archivo\n",
        "def export_file(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        file_name = file_name_input.value\n",
        "        file_format = format_dropdown.value\n",
        "        if file_format == 'csv':\n",
        "            dfClusterizado.to_csv(f\"{file_name}.csv\", index=False)\n",
        "            print(f\"Archivo {file_name}.csv exportado exitosamente.\")\n",
        "        elif file_format == 'json':\n",
        "            dfClusterizado.to_json(f\"{file_name}.json\", orient='records', lines=True)\n",
        "            print(f\"Archivo {file_name}.json exportado exitosamente.\")\n",
        "\n",
        "export_button.on_click(export_file)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(format_dropdown, file_name_input, export_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiiL8gizB73W"
      },
      "source": [
        "### **(POSTPROCESAMIENTO PROVISIONAL PARA COSMOGRAPH):**\n",
        "\n",
        "**Receta de OpenRefine** para preparar dataset clusterizado para su visualización en **Cosmograph**:\n",
        "\n",
        "- Renombrar columna con identificador único id a **id**, en caso de que no exista.\n",
        "- Crear columna **cluster-str** basada en cluster. Cambiar valores a letras con faceta de texto o con el script de python siguiente:\n",
        "\n",
        "\n",
        "```\n",
        "# Define a mapping from numbers to letters\n",
        "number_to_letter = {\n",
        "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',\n",
        "    5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
        "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O',\n",
        "    15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T'\n",
        "}\n",
        "\n",
        "# The value of the cell is stored in the variable 'value'\n",
        "# Convert value to integer, if it's a string representation of a number\n",
        "# and then get the corresponding letter, if the number is between 0 and 19\n",
        "try:\n",
        "    # Assuming 'value' is the cell value, make sure it is an integer\n",
        "    number = int(value)\n",
        "    # Return the corresponding letter if the number is between 0 and 19\n",
        "    if 0 <= number <= 19:\n",
        "        return number_to_letter[number]\n",
        "    else:\n",
        "        return value  # Return the original value if not in the specified range\n",
        "except ValueError:\n",
        "    # Return the original value if it is not a number\n",
        "    return value\n",
        "```\n",
        "\n",
        "\n",
        "- Crear nueva columna **x**  a partir de reduced_embeddings. Aplicar transformación de celda con el siguiente script de Python:\n",
        "\n",
        "\n",
        "```\n",
        "import ast\n",
        "\n",
        "# Convert the string to a list using ast.literal_eval()\n",
        "value_list = ast.literal_eval(value)\n",
        "\n",
        "# Get the first element of the list\n",
        "x = value_list[0]\n",
        "\n",
        "return x\n",
        "```\n",
        "\n",
        "\n",
        "- Crear nueva columna **y** a partir de reduced_embeddings. Aplicar transformación de celda con el siguiente script de Python:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import ast\n",
        "\n",
        "# Convert the string to a list using ast.literal_eval()\n",
        "value_list = ast.literal_eval(value)\n",
        "\n",
        "# Get the first element of the list\n",
        "y = value_list[1]\n",
        "\n",
        "return y\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4OQBbdRsRRd"
      },
      "source": [
        "## **5. Referencias:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvDL8Tfgr_6s"
      },
      "source": [
        "* Bird, Steven, Edward Loper & Ewan Klein (2009). Natural Language Processing with Python.  O'Reilly Media Inc.\n",
        "* McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426. https://arxiv.org/abs/1802.03426\n",
        "* Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E., & others. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\n",
        "* Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (arXiv:1908.10084). arXiv. http://arxiv.org/abs/1908.10084\n",
        "* Rousseeuw, P. (1987). Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics. 20: 53–65. doi:10.1016/0377-0427(87)90125-7.\n",
        "* Spärck-Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28(1), 11-21. https://www.staff.city.ac.uk/~sbrp622/idfpapers/ksj_orig.pdf\n",
        "* Thorndike, R. (1953). Who Belongs in the Family?. Psychometrika. 18 (4): 267–276. doi:10.1007/BF02289263. S2CID 120467216.\n",
        "* Wang, L., Yang, N., Huang, X., Yang, L., Majumder, R., & Wei, F. (2024). Multilingual E5 Text Embeddings: A Technical Report. arXiv preprint arXiv:2402.05672. Recuperado de https://arxiv.org/abs/2402.05672\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASBLPGoSNBqe"
      },
      "source": [
        "## **6. Créditos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdAyvK0mOkwZ"
      },
      "source": [
        "**Realizado por el equipo de Signa_Lab ITESO:**\n",
        "\n",
        "- **Programación de cuadernos de código (Python)**:\n",
        "Javier de la Torre Silva, José Luis Almendarez González y Diego Arredondo Ortiz\n",
        "\n",
        "- **Supervisión del desarrollo tecnológico y documentación:**\n",
        "Diego Arredondo Ortiz\n",
        "\n",
        "- **Equipo de Coordinación Signa_Lab ITESO:**\n",
        "Paloma López Portillo Vázquez, Víctor Hugo Ábrego Molina y Eduardo G. de Quevedo Sánchez\n",
        "\n",
        "Mayo, 2024. Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO)\n",
        "Tlaquepaque, Jalisco, México.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
