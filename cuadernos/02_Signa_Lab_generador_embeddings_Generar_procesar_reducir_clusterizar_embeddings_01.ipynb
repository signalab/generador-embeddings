{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFHaGxXuNcOT"
      },
      "source": [
        "# **Signa_Lab ITESO:** Generador de *Embbeddings*\n",
        "\n",
        "## **Cuaderno 02:** Generación de *embeddings*, reducción de dimensionalidades y clusterización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0UWcYzNjsq"
      },
      "source": [
        "Cuaderno de código para generar *embeddings* (relaciones semánticas codificadas en vectores) a partir de datos textuales, idealmente, procesados y depurados con antelación ([ver cuaderno 01](https://github.com/signalab/generador-embeddings/blob/main/cuadernos/01_Signa_Lab_generador_embeddings_Depuraci%C3%B3n_importar_limpiar_depurar_texto_01.ipynb)), con ayuda de modelos de lenguaje de la librería [sentence-transformers](https://www.sbert.net/), alojados en repositorios de [HuggingFace](https://huggingface.co/sentence-transformers) (en la nube) o descargados localmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EHlbspzMJyO"
      },
      "source": [
        "## 1. Importar librerías, dependencias y archivo de datos a para la generación de *embeddings*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23B1fl0tWOI"
      },
      "source": [
        "**Instalar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXLwyzU7vuH"
      },
      "outputs": [],
      "source": [
        "# Instalar librerías de Python necesarias\n",
        "\n",
        "!pip install tensorflow_text\n",
        "!pip install pandas\n",
        "!pip install sentence_transformers\n",
        "!pip install numpy\n",
        "!pip install operator\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install plotly\n",
        "!pip install umap-learn\n",
        "!pip install yellowbrick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1KawEEvNsWa"
      },
      "source": [
        "**Importar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlVhFJrFNtlt"
      },
      "outputs": [],
      "source": [
        "# Importar librerías de Python necesarias\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import operator\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch\n",
        "from transformers import BertForMaskedLM, BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "import operator\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn import datasets\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6IZmxNNk13m"
      },
      "outputs": [],
      "source": [
        "# Definir función para implementar barra de progreso sobre el procesamiento\n",
        "def with_progress_bar(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Inicia el contador de tiempo\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Crea una barra de progreso\n",
        "        pbar = tqdm(total=100, desc=\"Processing\", ncols=70)\n",
        "\n",
        "        # Define una función interna para actualizar la barra de progreso\n",
        "        def update_progress_bar(i):\n",
        "            pbar.update(i)\n",
        "\n",
        "        # Agrega la función de actualización al diccionario de argumentos\n",
        "        kwargs['update_progress_bar'] = update_progress_bar\n",
        "\n",
        "        # Ejecuta la función original\n",
        "        result = func(*args, **kwargs)\n",
        "\n",
        "        # Finaliza la barra de progreso\n",
        "        pbar.close()\n",
        "\n",
        "        # Calcula y muestra el tiempo de ejecución\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
        "\n",
        "        return result\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dgB2fTZk13n"
      },
      "source": [
        "**Cargar modelo de lenguaje** para su implementación en librería de *sentence-transformers*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv-AoqmSpMCG"
      },
      "outputs": [],
      "source": [
        "# Indicar ruta y nombre de modelo de lenguaje a cargar en librería de sentence transformers\n",
        "# puedes explorar los modelos incorporados a librería de sentence-transformers en su repositorio en HuggingFace: https://huggingface.co/sentence-transformers\n",
        "\n",
        "# ejemplo de ruta de modelo en la nube cargado desde Hugging Face:\n",
        "modelo = \"intfloat/multilingual-e5-large-instruct\"\n",
        "\n",
        "# ejemplo de ruta de modelo cargado localmente:\n",
        "# modelo = \"./modelos/multilingual-e5-large-instruct\"\n",
        "\n",
        "# cargar modelo para embeddings\n",
        "embedder = SentenceTransformer(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m32UcQATOp3"
      },
      "outputs": [],
      "source": [
        "embedder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyo8wtX6RV9z"
      },
      "source": [
        "**Indicar rutas y cargar archivos de datos** para generar *embeddings*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEyBteFFRVLB"
      },
      "outputs": [],
      "source": [
        "# PARA UN SOLO ARCHIVO (generar embeddings de un archivo individual):\n",
        "# especificar ruta y formato de archivo a importar:\n",
        "# ruta = \"./archivo-datos-para-embeddings.csv\" # importar CSV\n",
        "# ruta = \"./archivo-datos-para-embeddings.xlsx\" # importar Excel\n",
        "\n",
        "\n",
        "# extraer nombre de archivo como referencia\n",
        "# nombreArchivo = ruta.split(\"/\")[-1].split('.')[0]\n",
        "\n",
        "# crear data frame con archivo de datos importado\n",
        "# df = pd.read_csv(ruta)  # data frame desde CSV\n",
        "# df = pd.read_excel(ruta)  # data frame desde Excel\n",
        "\n",
        "\n",
        "\n",
        "# PARA MÚLTIPLES ARCHIVOS (generar embeddings para cada uno):\n",
        "# especificar rutas y formatos de distintos archivos a importar:\n",
        "ruta1 = \"./archivo-datos-para-embeddings1.csv\" # importar CSV\n",
        "ruta2 = \"./archivo-datos-para-embeddings2.csv\" # importar CSV\n",
        "ruta3 = \"./archivo-datos-para-embeddings3.csv\" # importar CSV\n",
        "\n",
        "# ruta1 = \"./archivo-datos-para-embeddings1.xlsx\" # importar Excel\n",
        "# ruta2 = \"./archivo-datos-para-embeddings2.xlsx\" # importar Excel\n",
        "# ruta3 = \"./archivo-datos-para-embeddings3.xlsx\" # importar Excel\n",
        "\n",
        "# crear data frames con archivos de datos importados\n",
        "df1 = pd.read_csv(ruta1)  # data frame desde CSV\n",
        "df2 = pd.read_csv(ruta2)  # data frame desde CSV\n",
        "df3 = pd.read_csv(ruta3)  # data frame desde CSV\n",
        "\n",
        "# df1 = pd.read_excel(ruta1)  # data frame desde Excel\n",
        "# df2 = pd.read_excel(ruta2)  # data frame desde Excel\n",
        "# df3 = pd.read_excel(ruta3)  # data frame desde Excel\n",
        "\n",
        "\n",
        "# extraer nombres de archivos como referencia\n",
        "nombreArchivo1 = ruta1.split(\"/\")[-1].split('.')[0]\n",
        "nombreArchivo2 = ruta2.split(\"/\")[-1].split('.')[0]\n",
        "nombreArchivo3 = ruta3.split(\"/\")[-1].split('.')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WsQEs5DT4Vo"
      },
      "source": [
        "**Revisar datos importados:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Pi3v0fweWi"
      },
      "source": [
        "**Para un solo archivo**, revisar registros importados desde archivo individual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK3TER2kT6Zw"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de datos importados de archivo individual\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT7qqnH_hm0Y"
      },
      "outputs": [],
      "source": [
        "# Verificar número de filas y columnas en datos importados de archivo individual\n",
        "# df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVtKAX-HwjQC"
      },
      "source": [
        "**Para múltiples archivos**, revisar registros importados desde cada ruta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CKqwW5UwpkZ"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de datos importados de 1er archivo (ruta1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUpwgP3Bwpka"
      },
      "outputs": [],
      "source": [
        "# Verificar número de filas y columnas en datos importados de 1er archivo (ruta1)\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JhJYdf1wwXh"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de datos importados de 2ndo archivo (ruta2)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCDMWUpQwwXh"
      },
      "outputs": [],
      "source": [
        "# Verificar número de filas y columnas en datos importados de 2ndo archivo (ruta2)\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkLNKHdqw86t"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de datos importados de 3er archivo (ruta3)\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dnrscEDw86t"
      },
      "outputs": [],
      "source": [
        "# Verificar número de filas y columnas en datos importados de 3er archivo (ruta3)\n",
        "df3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KybuZl2SEry"
      },
      "source": [
        "## 2. Generar *embeddings* con el modelo de lenguaje cargado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqapTyPNpWcm"
      },
      "source": [
        "**Definir función para generar embeddings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luMVyv37OCNP"
      },
      "outputs": [],
      "source": [
        "# Definir función para generar embeddings\n",
        "@with_progress_bar\n",
        "def generate(mod, dfl, colText, update_progress_bar=None):\n",
        "    tot = len(dfl)\n",
        "    dfW = dfl\n",
        "    dfW.loc[:, \"Embedding\"] = None\n",
        "    for index, row in dfW.iterrows():\n",
        "        # Iterar sobre el DataFrame y codificar cada texto\n",
        "        embedding = mod.encode(str(row[colText])).tolist()\n",
        "        dfW.at[index, 'Embedding'] = embedding\n",
        "        # Actualizar la barra de progreso una vez por cada 10 filas\n",
        "        if update_progress_bar is not None:\n",
        "            update_progress_bar((index/tot)*2)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj8CklhMSOZp"
      },
      "source": [
        "**Para un solo archivo**, generar embeddings con archivo de datos cargado en data frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0AlZb1MSJnc"
      },
      "outputs": [],
      "source": [
        "# Generar embeddings de un solo archivo\n",
        "\n",
        "# Indicar columna de data frame con texto a procesar\n",
        "# textCol = \"sem_text\"\n",
        "# Ejecutar generación de embeddings con datos y modelo cargados\n",
        "# datasetEmbeddings = generate(embedder, df, textCol)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para múltiples archivos**, generar embeddings por cada uno de los archivos de datos cargados en sus respectivos data frames:"
      ],
      "metadata": {
        "id": "ETSVPEeKsa5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2wPYHDUTOp7"
      },
      "outputs": [],
      "source": [
        "# Generar embeddings de 1er data frame (df1)\n",
        "\n",
        "# Indicar columna de data frame con texto a procesar\n",
        "textCol1 = \"sem_text\"\n",
        "# Ejecutar generación de embeddings con datos y modelo cargados\n",
        "datasetEmbeddings1 = generate(embedder, df1, textCol1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7Vb187lTOp8"
      },
      "outputs": [],
      "source": [
        "# Generar embeddings de 2ndo data frame (df2)\n",
        "\n",
        "# Indicar columna de data frame con texto a procesar\n",
        "textCol2 = \"sem_text\"\n",
        "# Ejecutar generación de embeddings con datos y modelo cargados\n",
        "datasetEmbeddings2 = generate(embedder, df2, textCol2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYM5fRIwTOp8"
      },
      "outputs": [],
      "source": [
        "# Generar embeddings de 2ndo data frame (df2)\n",
        "\n",
        "# Indicar columna de data frame con texto a procesar\n",
        "textCol3 = \"sem_text\"\n",
        "# Ejecutar generación de embeddings con datos y modelo cargados\n",
        "datasetEmbeddings3 = generate(embedder, df3, textCol3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-fP-hdfUCdx"
      },
      "source": [
        "**Exportar archivos de datos con embeddings generados (en formato CSV):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXGIRV0oUaR9"
      },
      "outputs": [],
      "source": [
        "# Exportar archivos de datos con embeddings en CSV:\n",
        "\n",
        "\n",
        "# Desde un solo archivo, exportar CSV con embeddings procesados:\n",
        "# df.to_csv(f\"{nombreArchivo}Embeddings.csv\")\n",
        "# print(f\"{nombreArchivo}Embeddings descargado en csv\")\n",
        "\n",
        "\n",
        "# Desde múltiples archivos, exportar CSVs con embeddings procesados por cada uno:\n",
        "df1.to_csv(f\"{nombreArchivo1}_Embeddings.csv\")\n",
        "df2.to_csv(f\"{nombreArchivo2}_Embeddings.csv\")\n",
        "df3.to_csv(f\"{nombreArchivo3}_Embeddings.csv\")\n",
        "\n",
        "\n",
        "print(f\"{nombreArchivo1}_Embeddings descargado en csv\")\n",
        "print(f\"{nombreArchivo2}_Embeddings descargado en csv\")\n",
        "print(f\"{nombreArchivo3}_Embeddings descargado en csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Reducción de dimensiones con distintas técnicas (UMAP, PCA, TSNE)**"
      ],
      "metadata": {
        "id": "oVoYsHAu7Vu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elegir data frame** con embeddings para reducir dimensionalidaes y clusterizar:"
      ],
      "metadata": {
        "id": "3Wd1bJ2I78ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegir data frame con embeddings (df, en caso de un solo archivo, df1,2,3... e caso de múltiples archivos:\n",
        "\n",
        "# Un solo archivo cargado con embeddings generados\n",
        "# dfClusters = df\n",
        "\n",
        "# Para múltiples archivos, elegir número de data frame y repetir proceso\n",
        "dfClusters = df1\n",
        "# dfClusters = df2\n",
        "# dfClusters = df3"
      ],
      "metadata": {
        "id": "7jkjqVrj8QIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir función para reducir dimensionalidades con: **UMAP**"
      ],
      "metadata": {
        "id": "9vcYVTm_7a-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir función para UMAP\n",
        "def genUMAP(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    umap_model = umap.UMAP(n_components=nDims)\n",
        "    X_umap = umap_model.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = X_umap.tolist()\n",
        "    return dfW"
      ],
      "metadata": {
        "id": "Xppikbye7dVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pInnYTLHbQNu"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7MnIWmVbPo_"
      },
      "outputs": [],
      "source": [
        "# Definir función para PCA\n",
        "def genPCA(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    pca = PCA(n_components=nDims)\n",
        "    X_pca = pca.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_pca)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCzptnIbV46"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **TSNE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPrc8VxubYG7"
      },
      "outputs": [],
      "source": [
        "# Definir función para TSNE\n",
        "def genTSNE(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    tsne = TSNE(n_components=nDims, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_tsne)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPasLSMzfsuO"
      },
      "source": [
        "**Definir función para elegir método para reducir dimensiones:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIBL8r8yfwJW"
      },
      "outputs": [],
      "source": [
        "def reduceDim(df, columnaEmbeddings, nDims, method):\n",
        "    if method.lower() == 'umap':\n",
        "        return genUMAP(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'pca':\n",
        "        return genPCA(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'tsne':\n",
        "        return genTSNE(df, columnaEmbeddings, nDims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3nKQlzIWNY"
      },
      "source": [
        "**Elegir método a utilizar, número de dimensiones (2D o 3D) y ejecutar reducción de dimensionalidades sobre *embeddings* cargados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLxWPxkAfglA"
      },
      "outputs": [],
      "source": [
        "#Indicar nombre de columna con embeddings completos (vector dado por las dimensiones del modelo de lenguaje)\n",
        "columnaConEmbeddings = \"Embedding\"\n",
        "\n",
        "#Indicar si se busca reducir a 2 o 3 dimensiones para visualizador 2D o 3D\n",
        "numDimensiones = 3\n",
        "\n",
        "# Elegir método para reducción de dimensionalidades: \"umap\", \"tsne\", \"pca\"\n",
        "metodo = \"umap\"\n",
        "\n",
        "# Ejecutar reducción de dimensionalidades\n",
        "datasetConDimensionesReducidas = reduceDim(dfClusters, columnaConEmbeddings, numDimensiones, metodo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFtGIdSqbEOZ"
      },
      "outputs": [],
      "source": [
        "datasetConDimensionesReducidas.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RTG4Qt9ccBu"
      },
      "source": [
        "## **4. Clusterización y visualización de *embeddings***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfTwsNNWcecc"
      },
      "source": [
        "Definir función para **Método del Codo** para calcular número ideal de clústers para los datos cargados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMmtd5NFcdqh"
      },
      "outputs": [],
      "source": [
        "def elbowMethod(df, columnWiEmbeddings, rangoPosibleDeCluster, byRegion=False):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWiEmbeddings].tolist())\n",
        "    # Calcula la inercia para diferentes valores de k (número de clústeres)\n",
        "    # Inicializa una lista vacía para almacenar los valores de inercia calculados para cada número de clústeres\n",
        "    inertia_values = []\n",
        "    # Define un rango de valores de k (número de clústeres) para probar, basándose en el rango proporcionado como argumento\n",
        "    possible_k_values = range(rangoPosibleDeCluster[0], rangoPosibleDeCluster[1]+1)  # Prueba k desde n1 hasta n2 clústeres\n",
        "\n",
        "    # Itera sobre el rango de posibles valores de k\n",
        "    for index, k in enumerate(possible_k_values):\n",
        "        # Inicializa el algoritmo KMeans con el número actual de clústeres (k) y una semilla aleatoria fija\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "        # Entrena el modelo KMeans con los embeddings\n",
        "        kmeans.fit(embeddings)\n",
        "\n",
        "        # Añade la inercia del modelo (la suma de las distancias cuadradas de las muestras a su centro de clúster más cercano) a la lista de valores de inercia\n",
        "        inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "    # Prepara los resultados para ser graficados, conteniendo los valores de k y las inercias correspondientes\n",
        "    resToPlot = [possible_k_values, inertia_values]\n",
        "\n",
        "    # Grafica el método del codo utilizando matplotlib, donde el eje X representa el número de clústeres y el eje Y la inercia\n",
        "    plt.plot(resToPlot[0], resToPlot[1], marker='o')\n",
        "    plt.xlabel('Número de Clústeres (k)')\n",
        "    plt.ylabel('Inercia')\n",
        "    plt.title('Método del Codo para Determinar k')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng9IUzHlguCH"
      },
      "source": [
        "**Ejecutar método del codo** para identificar número deseable de clústers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0pCw4dSgxxh"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Calcular número ideal en un rango de 1 a 20 clústers\n",
        "rangoDeClusters = [1,20]\n",
        "elbowMethod(datasetConDimensionesReducidas, columnaConEmbeddings, rangoDeClusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgGoiC-85QEh"
      },
      "source": [
        "Definir función para **Método de Silueta** para calcular número ideal de clústers para los datos cargados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coX058Qt5Pmm"
      },
      "outputs": [],
      "source": [
        "def silhouetteMethod(df, columnWithEmbeddings, rangeOfClusters):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWithEmbeddings].tolist())\n",
        "\n",
        "    # Establece el número de subplots basado en el rango de clústeres a analizar\n",
        "    n_clusters = range(rangeOfClusters[0], rangeOfClusters[1] + 1)\n",
        "    n_rows = len(n_clusters) // 2 + len(n_clusters) % 2\n",
        "    fig, ax = plt.subplots(n_rows, 2, figsize=(16, 32))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "    # Itera sobre el rango especificado de número de clústeres\n",
        "    for i, k in enumerate(n_clusters):\n",
        "        # Crea una instancia de KMeans para el número actual de clústeres\n",
        "        km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
        "\n",
        "        # Calcula la fila y columna para el subplot actual\n",
        "        q, mod = divmod(i, 2)\n",
        "\n",
        "        # Crea una instancia de SilhouetteVisualizer para visualizar el coeficiente de silueta\n",
        "        visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q][mod])\n",
        "\n",
        "        # Ajusta el visualizador con los embeddings\n",
        "        visualizer.fit(embeddings)\n",
        "\n",
        "        # Establece el título del subplot\n",
        "        ax[q][mod].set_title(f'Clusters: {k}')\n",
        "\n",
        "    # Ajusta la disposición de los subplots para evitar solapamientos\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUt22TJUKG1G"
      },
      "outputs": [],
      "source": [
        "# Ejecutar función de método de silueta\n",
        "silhouetteMethod(dfClusters, 'embeddingsReducidos', (2, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCgFS0ucg0n"
      },
      "source": [
        "Definir función de clusterizarización utilizando método **K-Means:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m26wIKEciSI"
      },
      "outputs": [],
      "source": [
        "# Definir función de clusterización con K-means\n",
        "def clusterKmeans(df, optimal_k_value, columnaEmbeddings, byRegion=False, cluster_col_name=None):\n",
        "    embeddings = df[columnaEmbeddings].tolist()\n",
        "    dfW = df.copy() # Crear copia de trabajo de DataFrame\n",
        "\n",
        "    if cluster_col_name is None:\n",
        "      cluster_col_name = \"cluster\"\n",
        "\n",
        "    try:\n",
        "        if byRegion: # Clusterización por región (opcional, no utilizado en metodología final)\n",
        "            # Inicializar nueva columna para alojar etiquetas de clústeres\n",
        "            dfW[cluster_col_name] = None\n",
        "\n",
        "            # Iterar sobre cada región (opcional)\n",
        "            for region, df_region in dfW.groupby('region'):\n",
        "                # Aplicar clusterización de K-means en cada región (opcional)\n",
        "                kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "                cluster_labels = kmeans.fit_predict(df_region[columnaEmbeddings].tolist())\n",
        "\n",
        "                # Añadir prefijo de clúster por región (opcional)\n",
        "                prefixed_cluster_labels = [f\"{region}_{label}\" for label in cluster_labels]\n",
        "\n",
        "                # Asignar etiquetas de clúster por región a DataFrame\n",
        "                dfW.loc[dfW['region'] == region, cluster_col_name] = prefixed_cluster_labels\n",
        "        else:\n",
        "            # Aplicar clusterización por K-means a todo el conjunto de datos importado (versión implementada en metodología final)\n",
        "            kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "            cluster_labels = kmeans.fit_predict(embeddings)\n",
        "            dfW[cluster_col_name] = cluster_labels\n",
        "\n",
        "        return dfW\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar clusters: {e}\")\n",
        "        return pd.DataFrame({0: [\"Error al generar clusters\"]})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8e-qbFYhV3a"
      },
      "source": [
        "**Ejecutar clusterización** con número deseado de clúster con método *k-means:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYDZGoBShW-2"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Indicar número de clústers a segmentar\n",
        "numeroDeClusters = 7\n",
        "dfClusterizado = clusterKmeans(datasetConDimensionesReducidas, numeroDeClusters, columnaConEmbeddings, byRegion=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSnflYhvvupM"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de registros con sus respectivos clústers asignados\n",
        "dfClusterizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65amorfRec8J"
      },
      "source": [
        "Definir función para **visualizar relaciones semánticas y clústeres en 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvxpKaLbeltl"
      },
      "outputs": [],
      "source": [
        "def visualize3D(df, columnaEmbeddingsReducidas, columnaTexto, byRegion=False, columnaCluster=None):\n",
        "  if columnaCluster is None:\n",
        "    columnaCluster = \"cluster\"\n",
        "  embeddingWithSelectedDimensions = df[columnaEmbeddingsReducidas].tolist()\n",
        "  dfToPlot = {\n",
        "        \"X\": [x[0] for x in embeddingWithSelectedDimensions],\n",
        "        \"Y\": [y[1] for y in embeddingWithSelectedDimensions],\n",
        "        \"Z\": [z[2] for z in embeddingWithSelectedDimensions],\n",
        "        \"cluster\": df[columnaCluster].tolist(),\n",
        "        \"text\": df[columnaTexto]\n",
        "  }\n",
        "\n",
        "  fig = px.scatter_3d(dfToPlot, x='X', y='Y', z='Z', color='cluster', hover_data=[\"text\"],\n",
        "                         labels={'X': 'Dimensión 1', 'Y': 'Dimensión 2', 'Z': 'Dimensión 3'},\n",
        "                         title=f'Visualización de clústers semánticos',\n",
        "                         color_discrete_sequence=px.colors.sequential.Viridis)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97inR3riC6g"
      },
      "source": [
        "**Ejecutar visualización de clústers 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtVgG0BRiFSl",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Indicar columna de texto para etiquetas\n",
        "columnaTextoClusterizado = \"clean_text\"\n",
        "visualize3D(dfClusterizado, columnaConEmbeddings, columnaTextoClusterizado, columnaCluster=\"cluster\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_elu-UcSfhWH"
      },
      "source": [
        "**Exportar archivos de datos (formato CSV y JSON) con clústers calculados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et8wiYQFiXI1"
      },
      "outputs": [],
      "source": [
        "# Exportar en json, haciendo referencia al data frame elegido\n",
        "dfClusterizado.to_json(f\"{nombreArchivo1}_Clusters.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hzc5r3uiXWD"
      },
      "outputs": [],
      "source": [
        "# Exportar en csv, haciendo referencia al data frame elegido\n",
        "dfClusterizado.to_csv(f\"{nombreArchivo1}_Clusters.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(POSTPROCESAMIENTO PROVISIONAL PARA COSMOGRAPH):**\n",
        "\n",
        "**Receta de OpenRefine** para preparar dataset clusterizado para su visualización en **Cosmograph**:\n",
        "\n",
        "- Renombrar columna con identificador único id a **id**, en caso de que no exista.\n",
        "- Crear columna **cluster-str** basada en cluster. Cambiar valores a letras con faceta de texto o con el script de python siguiente:\n",
        "\n",
        "\n",
        "```\n",
        "# Define a mapping from numbers to letters\n",
        "number_to_letter = {\n",
        "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',\n",
        "    5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
        "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O',\n",
        "    15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T'\n",
        "}\n",
        "\n",
        "# The value of the cell is stored in the variable 'value'\n",
        "# Convert value to integer, if it's a string representation of a number\n",
        "# and then get the corresponding letter, if the number is between 0 and 19\n",
        "try:\n",
        "    # Assuming 'value' is the cell value, make sure it is an integer\n",
        "    number = int(value)\n",
        "    # Return the corresponding letter if the number is between 0 and 19\n",
        "    if 0 <= number <= 19:\n",
        "        return number_to_letter[number]\n",
        "    else:\n",
        "        return value  # Return the original value if not in the specified range\n",
        "except ValueError:\n",
        "    # Return the original value if it is not a number\n",
        "    return value\n",
        "```\n",
        "\n",
        "\n",
        "- Crear nueva columna **x**  a partir de reduced_embeddings. Aplicar transformación de celda con el siguiente script de Python:\n",
        "\n",
        "\n",
        "```\n",
        "import ast\n",
        "\n",
        "# Convert the string to a list using ast.literal_eval()\n",
        "value_list = ast.literal_eval(value)\n",
        "\n",
        "# Get the first element of the list\n",
        "x = value_list[0]\n",
        "\n",
        "return x\n",
        "```\n",
        "\n",
        "\n",
        "- Crear nueva columna **y** a partir de reduced_embeddings. Aplicar transformación de celda con el siguiente script de Python:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import ast\n",
        "\n",
        "# Convert the string to a list using ast.literal_eval()\n",
        "value_list = ast.literal_eval(value)\n",
        "\n",
        "# Get the first element of the list\n",
        "y = value_list[1]\n",
        "\n",
        "return y\n",
        "```"
      ],
      "metadata": {
        "id": "xiiL8gizB73W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4OQBbdRsRRd"
      },
      "source": [
        "## **5. Referencias:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvDL8Tfgr_6s"
      },
      "source": [
        "* Bird, Steven, Edward Loper & Ewan Klein (2009). Natural Language Processing with Python.  O'Reilly Media Inc.\n",
        "* McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426. https://arxiv.org/abs/1802.03426\n",
        "* Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E., & others. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\n",
        "* Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (arXiv:1908.10084). arXiv. http://arxiv.org/abs/1908.10084\n",
        "* Rousseeuw, P. (1987). Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics. 20: 53–65. doi:10.1016/0377-0427(87)90125-7.\n",
        "* Spärck-Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28(1), 11-21. https://www.staff.city.ac.uk/~sbrp622/idfpapers/ksj_orig.pdf\n",
        "* Thorndike, R. (1953). Who Belongs in the Family?. Psychometrika. 18 (4): 267–276. doi:10.1007/BF02289263. S2CID 120467216.\n",
        "* Wang, L., Yang, N., Huang, X., Yang, L., Majumder, R., & Wei, F. (2024). Multilingual E5 Text Embeddings: A Technical Report. arXiv preprint arXiv:2402.05672. Recuperado de https://arxiv.org/abs/2402.05672\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Créditos**"
      ],
      "metadata": {
        "id": "ASBLPGoSNBqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizado por el equipo de Signa_Lab ITESO:**\n",
        "\n",
        "- **Programación de cuadernos de código (Python)**:\n",
        "Javier de la Torre Silva, José Luis Almendarez González y Diego Arredondo Ortiz\n",
        "\n",
        "- **Supervisión del desarrollo tecnológico y documentación:**\n",
        "Diego Arredondo Ortiz\n",
        "\n",
        "- **Equipo de Coordinación Signa_Lab ITESO:**\n",
        "Paloma López Portillo Vázquez, Víctor Hugo Ábrego Molina y Eduardo G. de Quevedo Sánchez\n",
        "\n",
        "Mayo, 2024. Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO)\n",
        "Tlaquepaque, Jalisco, México.\n"
      ],
      "metadata": {
        "id": "fdAyvK0mOkwZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}