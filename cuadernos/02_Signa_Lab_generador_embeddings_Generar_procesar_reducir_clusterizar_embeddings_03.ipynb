{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFHaGxXuNcOT"
      },
      "source": [
        "# **Signa_Lab ITESO:** Generador de *Embbeddings*\n",
        "\n",
        "## **Cuaderno 02:** Generación de *embeddings*, reducción de dimensionalidades y clusterización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id0UWcYzNjsq"
      },
      "source": [
        "Cuaderno de código para generar *embeddings* (relaciones semánticas codificadas en vectores) a partir de datos textuales, idealmente, procesados y depurados con antelación ([ver cuaderno 01](https://github.com/signalab/generador-embeddings/blob/main/cuadernos/01_Signa_Lab_generador_embeddings_Depuraci%C3%B3n_importar_limpiar_depurar_texto_01.ipynb)), con ayuda de modelos de lenguaje de la librería [sentence-transformers](https://www.sbert.net/), alojados en repositorios de [HuggingFace](https://huggingface.co/sentence-transformers) (en la nube) o descargados localmente.\n",
        "\n",
        "**\\***Los grupos de celdas marcadas con **asterisco requieren información** antes de seguir adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EHlbspzMJyO"
      },
      "source": [
        "## 1. Importar librerías, archivos de datos y modelos de lenguaje para la generación de *embeddings*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalar e importar librerías:"
      ],
      "metadata": {
        "id": "-VJl3gf3A1RM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23B1fl0tWOI"
      },
      "source": [
        "**Instalar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXLwyzU7vuH",
        "outputId": "0b7fe275-a497-4000-bd68-c678a70ec340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.21.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow<2.19,>=2.18.0 (from tensorflow_text)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.67.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18.0->tensorflow_text)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow_text) (0.1.2)\n",
            "Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Instalar librerías de Python necesarias\n",
        "!pip install nbformat\n",
        "!pip install tf-keras\n",
        "!pip install tensorflow_text\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install numpy\n",
        "!pip install operator\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "!pip install nltk\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install plotly\n",
        "!pip install umap-learn\n",
        "!pip install yellowbrick\n",
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1KawEEvNsWa"
      },
      "source": [
        "**Importar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlVhFJrFNtlt"
      },
      "outputs": [],
      "source": [
        "# Importar librerías de Python necesarias\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "import nltk\n",
        "\n",
        "from sklearn import datasets\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6IZmxNNk13m"
      },
      "outputs": [],
      "source": [
        "# Definir función para implementar barra de progreso sobre el procesamiento\n",
        "def with_progress_bar(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # Inicia el contador de tiempo\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Crea una barra de progreso\n",
        "        pbar = tqdm(total=100, desc=\"Processing\", ncols=70)\n",
        "\n",
        "        # Define una función interna para actualizar la barra de progreso\n",
        "        def update_progress_bar(i):\n",
        "            pbar.update(i)\n",
        "\n",
        "        # Agrega la función de actualización al diccionario de argumentos\n",
        "        kwargs['update_progress_bar'] = update_progress_bar\n",
        "\n",
        "        # Ejecuta la función original\n",
        "        result = func(*args, **kwargs)\n",
        "\n",
        "        # Finaliza la barra de progreso\n",
        "        pbar.close()\n",
        "\n",
        "        # Calcula y muestra el tiempo de ejecución\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
        "\n",
        "        return result\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugJGAWJg2aq1"
      },
      "source": [
        "### *Indicar rutas de archivos de datos a importar y nombre de proyecto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2bCEoXE2aq1"
      },
      "outputs": [],
      "source": [
        "# Definir función para cargar archivos a partir de la extensión en su ruta indicada\n",
        "def load_file(path, encoding='utf-8'):\n",
        "    if path.endswith('.csv'):\n",
        "        return pd.read_csv(path, encoding=encoding)\n",
        "    elif path.endswith('.xlsx'):\n",
        "        return pd.read_excel(path)\n",
        "    else:\n",
        "        raise ValueError(\"Formato no compatible. Por favor carga solo archivos .csv or .xlsx.\")\n",
        "\n",
        "# Inicializar lista para alojar todas las rutas y una variable para el DataFrame final, accesible globalmente\n",
        "file_paths = []\n",
        "dfs = []\n",
        "df = None  # DataFrame global\n",
        "\n",
        "# Lista de codificaciones comunes\n",
        "encoding_options = ['utf-8', 'latin1', 'ISO-8859-1']\n",
        "\n",
        "# Dropdown para seleccionar la codificación del archivo\n",
        "encoding_dropdown = widgets.Dropdown(\n",
        "    options=encoding_options,\n",
        "    value='utf-8',\n",
        "    description='Codificación:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Campo de texto (input) para indicar nombre del proyecto (para integrarse en nombres de archivos a exportar)\n",
        "project_name = widgets.Text(value='', placeholder='Escribe el nombre del proyecto (corto y sin espacios)', description='Nombre del proyecto:')\n",
        "\n",
        "# Botones para añadir y eliminar archivos\n",
        "add_button = widgets.Button(description=\"Añadir archivo\", button_style='')\n",
        "remove_button = widgets.Button(description=\"Eliminar archivo\", button_style='warning')\n",
        "load_button = widgets.Button(description=\"Cargar archivos\", button_style='primary')\n",
        "\n",
        "# Lista para almacenar los widgets de rutas de archivos\n",
        "file_paths_widgets = []\n",
        "\n",
        "# Función para añadir un campo de texto para la ruta del archivo\n",
        "def add_file_input(b=None):\n",
        "    file_path = widgets.Text(value='', placeholder='Escribe la ruta del archivo', description='Ruta del archivo:')\n",
        "    file_paths_widgets.append(file_path)\n",
        "    update_ui()\n",
        "\n",
        "# Función para eliminar el último campo de texto de la ruta del archivo\n",
        "def remove_file_input(b=None):\n",
        "    if file_paths_widgets:\n",
        "        file_paths_widgets.pop()\n",
        "    update_ui()\n",
        "\n",
        "# Función para procesar los archivos\n",
        "def process_files(b=None):\n",
        "    global df\n",
        "    dfs.clear()\n",
        "    for file_path in file_paths_widgets:\n",
        "        path = file_path.value\n",
        "        try:\n",
        "            temp_df = load_file(path, encoding=encoding_dropdown.value)\n",
        "            dfs.append(temp_df)\n",
        "            print(f\"Nombre de archivo: {path}\")\n",
        "            print(f\"Filas/Columnas (shape): {temp_df.shape}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error al cargar el archivo {path}: {e}\")\n",
        "            return\n",
        "\n",
        "    if dfs:\n",
        "        df = pd.concat(dfs, ignore_index=True)  # Concatenate all DataFrames\n",
        "        print(\"\\n¡Se cargaron todos los archivos!\")\n",
        "        print(f\"Filas/Columnas (shape) de DataFrame creado: {df.shape}\")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para actualizar las opciones del dropdown de columnas\n",
        "def update_column_options():\n",
        "    if df is not None:\n",
        "        column_dropdown.options = df.columns.tolist()\n",
        "\n",
        "# Definir función para actualizar UI\n",
        "def update_ui():\n",
        "    clear_output()\n",
        "    display(project_name)\n",
        "    display(encoding_dropdown)\n",
        "    for path_input in file_paths_widgets:\n",
        "        display(path_input)\n",
        "    display(widgets.HBox([add_button, remove_button]))\n",
        "    display(load_button)\n",
        "    display(output)\n",
        "\n",
        "# Inicializar UI con un campo de texto (input) para ruta de archivo\n",
        "add_file_input()\n",
        "\n",
        "# Conectar botones a funciones\n",
        "add_button.on_click(add_file_input)\n",
        "remove_button.on_click(remove_file_input)\n",
        "load_button.on_click(process_files)\n",
        "\n",
        "# Mostrar la UI inicial\n",
        "update_ui()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previsualizar datos importados:"
      ],
      "metadata": {
        "id": "qbw5IfbABQxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK3TER2kT6Zw"
      },
      "outputs": [],
      "source": [
        "# Imprimir columnas e información sobre datos importados\n",
        "df.info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsualizar dataframe con CSVs importados\n",
        "df"
      ],
      "metadata": {
        "id": "PvRSIjKLBjV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Indicar e importar modelo de lenguaje:"
      ],
      "metadata": {
        "id": "cjDYVGEsBr4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importar modelo de lenguaje para búsqueda semántica:**\n",
        "\n",
        "\\* Para ejecutar consultas de búsqueda semántica, se debe cargar el mismo modelo de lenguaje que el utilizado para generar *embeddings* en los datos importados. Por default, se cargará el modelo de software libre [intfloat/multilingual-e5-large-instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct) (Wang et al, 2024), con la librería de aprendizaje profundo [sentence-transformers](https://www.sbert.net/) (Reimers & Gurevych, 2019), pero pueden utilizarse otros del [repositorio en Hugging Face](https://huggingface.co/sentence-transformers) de dicha librería o cargados localmente."
      ],
      "metadata": {
        "id": "C7QnsvE9Bw0e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dgB2fTZk13n"
      },
      "source": [
        "**Cargar modelo de lenguaje** para su implementación en librería de *sentence-transformers*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv-AoqmSpMCG"
      },
      "outputs": [],
      "source": [
        "embedder = None\n",
        "\n",
        "pre_tested_models = [\n",
        "    \"intfloat/multilingual-e5-large-instruct\",\n",
        "    \"all-mpnet-base-v2\",\n",
        "    \"all-MiniLM-L12-v2\",\n",
        "    \"paraphrase-multilingual-mpnet-base-v2\",\n",
        "    \"facebook-dpr-ctx_encoder-multiset-base\"\n",
        "]\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=pre_tested_models + [\"other or local\"],\n",
        "    value=pre_tested_models[0],\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "custom_model_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter custom model path',\n",
        "    description='Custom Path:',\n",
        "    disabled=True\n",
        ")\n",
        "\n",
        "confirm_button = widgets.Button(\n",
        "    description='Aceptar',\n",
        "    disabled=False,\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_model_change(change):\n",
        "    if change['new'] == \"other or local\":\n",
        "        custom_model_input.disabled = False\n",
        "    else:\n",
        "        custom_model_input.disabled = True\n",
        "\n",
        "model_dropdown.observe(on_model_change, names='value')\n",
        "\n",
        "def load_model(b):\n",
        "    global embedder\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        model_path = model_dropdown.value\n",
        "        if model_path == \"other or local\":\n",
        "            model_path = custom_model_input.value\n",
        "        embedder = SentenceTransformer(model_path)\n",
        "        print(f\"Model loaded from: {model_path}\")\n",
        "\n",
        "confirm_button.on_click(load_model)\n",
        "\n",
        "display(model_dropdown, custom_model_input, confirm_button, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m32UcQATOp3"
      },
      "outputs": [],
      "source": [
        "print(embedder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KybuZl2SEry"
      },
      "source": [
        "## 2. Generar *embeddings* con el modelo de lenguaje cargado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \\*Elegir columna de texto para generar *embeddings* en datos cargados:"
      ],
      "metadata": {
        "id": "HY2TjRZHCFP8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqapTyPNpWcm"
      },
      "source": [
        "**Definir función para generar embeddings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luMVyv37OCNP"
      },
      "outputs": [],
      "source": [
        "# Definir función para generar embeddings\n",
        "@with_progress_bar\n",
        "def generate(mod, dfl, colText, update_progress_bar=None):\n",
        "    tot = len(dfl)\n",
        "    dfW = dfl\n",
        "    dfW.loc[:, \"Embedding\"] = None\n",
        "    for index, row in dfW.iterrows():\n",
        "        # Iterar sobre el DataFrame y codificar cada texto\n",
        "        embedding = mod.encode(str(row[colText])).tolist()\n",
        "        dfW.at[index, 'Embedding'] = embedding\n",
        "        # Actualizar la barra de progreso una vez por cada 10 filas\n",
        "        if update_progress_bar is not None:\n",
        "            update_progress_bar((index/tot)*2)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj8CklhMSOZp"
      },
      "source": [
        "**Para un solo archivo**, generar embeddings con archivo de datos cargado en data frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0AlZb1MSJnc"
      },
      "outputs": [],
      "source": [
        "# Dropdown para seleccionar la columna del DataFrame\n",
        "column_dropdown = widgets.Dropdown(\n",
        "    options=df.columns.tolist(),\n",
        "    description='Columna:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y generar los embeddings\n",
        "generate_button = widgets.Button(\n",
        "    description='Generar Embeddings',\n",
        "    disabled=False,\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para generar los embeddings\n",
        "def generate_embeddings(b):\n",
        "    global datasetEmbeddings\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        textCol = column_dropdown.value\n",
        "        # Asegúrate de que embedder esté definido globalmente\n",
        "        datasetEmbeddings = generate(embedder, df, textCol)\n",
        "        print(f\"Embeddings generados para la columna: {textCol}\")\n",
        "\n",
        "generate_button.on_click(generate_embeddings)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(column_dropdown, generate_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previsualizar *embeddings* generados:"
      ],
      "metadata": {
        "id": "aMLTMg7DCah9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Previsualizar tabla con embeddings:**"
      ],
      "metadata": {
        "id": "xOMd3ci5CsXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjEQ-N772aq5"
      },
      "outputs": [],
      "source": [
        "datasetEmbeddings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-fP-hdfUCdx"
      },
      "source": [
        "### \\*Exportar archivos de datos con *embeddings* generados (en formato CSV):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXGIRV0oUaR9"
      },
      "outputs": [],
      "source": [
        "# Input de texto para el nombre del archivo\n",
        "file_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe el nombre del archivo',\n",
        "    description='Nombre Archivo:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para exportar el archivo\n",
        "export_button = widgets.Button(\n",
        "    description='Exportar CSV',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para exportar el archivo CSV\n",
        "def export_csv(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        nombreArchivo = file_name_input.value\n",
        "        datasetEmbeddings.to_csv(f\"{nombreArchivo}Embeddings.csv\")\n",
        "        print(f\"{nombreArchivo}Embeddings descargado en csv\")\n",
        "\n",
        "export_button.on_click(export_csv)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(file_name_input, export_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVoYsHAu7Vu4"
      },
      "source": [
        "## **3. Reducción de dimensiones con distintas técnicas (UMAP, PCA, TSNE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Elegir método para reducción de dimensionalidades:"
      ],
      "metadata": {
        "id": "bshcLIAYDXiq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wd1bJ2I78ja"
      },
      "source": [
        "**Elegir data frame** con embeddings para reducir dimensionalidaes y clusterizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jkjqVrj8QIa"
      },
      "outputs": [],
      "source": [
        "# Elegir data frame con embeddings (df, en caso de un solo archivo, df1,2,3... e caso de múltiples archivos:\n",
        "\n",
        "# Un solo archivo cargado con embeddings generados\n",
        "dfClusters = datasetEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcYVTm_7a-y"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **UMAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xppikbye7dVy"
      },
      "outputs": [],
      "source": [
        "# Definir función para UMAP\n",
        "def genUMAP(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    umap_model = umap.UMAP(n_components=nDims)\n",
        "    X_umap = umap_model.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = X_umap.tolist()\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pInnYTLHbQNu"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7MnIWmVbPo_"
      },
      "outputs": [],
      "source": [
        "# Definir función para PCA\n",
        "def genPCA(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    pca = PCA(n_components=nDims)\n",
        "    X_pca = pca.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_pca)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCzptnIbV46"
      },
      "source": [
        "Definir función para reducir dimensionalidades con: **TSNE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPrc8VxubYG7"
      },
      "outputs": [],
      "source": [
        "# Definir función para TSNE\n",
        "def genTSNE(df, columnaEmbeddings, nDims):\n",
        "    dfW = df\n",
        "    tsne = TSNE(n_components=nDims, random_state=42)\n",
        "    X_tsne = tsne.fit_transform(dfW[columnaEmbeddings].tolist())\n",
        "    dfW[\"embeddingsReducidos\"] = list(X_tsne)\n",
        "    return dfW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPasLSMzfsuO"
      },
      "source": [
        "**Definir función para elegir método para reducir dimensiones:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIBL8r8yfwJW"
      },
      "outputs": [],
      "source": [
        "def reduceDim(df, columnaEmbeddings, nDims, method):\n",
        "    if method.lower() == 'umap':\n",
        "        return genUMAP(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'pca':\n",
        "        return genPCA(df, columnaEmbeddings, nDims)\n",
        "    elif method.lower() == 'tsne':\n",
        "        return genTSNE(df, columnaEmbeddings, nDims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3nKQlzIWNY"
      },
      "source": [
        "**Elegir método a utilizar, número de dimensiones (2D o 3D) y ejecutar reducción de dimensionalidades sobre *embeddings* cargados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLxWPxkAfglA"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings completos (vector dado por las dimensiones del modelo de lenguaje)\n",
        "columnaConEmbeddings = \"Embedding\"\n",
        "\n",
        "# Indicar si se busca reducir a 2 o 3 dimensiones para visualizador 2D o 3D\n",
        "numDimensiones = 3\n",
        "\n",
        "# Dropdown para elegir el método de reducción de dimensionalidades\n",
        "metodo_dropdown = widgets.Dropdown(\n",
        "    options=[\"umap\", \"pca\", \"tsne\"],\n",
        "    value=\"umap\",\n",
        "    description='Método:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y ejecutar la reducción de dimensionalidades\n",
        "reduce_button = widgets.Button(\n",
        "    description='Reducir Dimensiones',\n",
        "    disabled=False,\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para ejecutar la reducción de dimensionalidades\n",
        "def reducir_dimensiones(b):\n",
        "    global datasetConDimensionesReducidas\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        metodo = metodo_dropdown.value\n",
        "        datasetConDimensionesReducidas = reduceDim(dfClusters, columnaConEmbeddings, numDimensiones, metodo)\n",
        "        print(f\"Reducción de dimensionalidades completada usando el método: {metodo}\")\n",
        "\n",
        "reduce_button.on_click(reducir_dimensiones)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(metodo_dropdown, reduce_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previsualizar tabla con *embeddings* reducidos a 3 dimensiones:"
      ],
      "metadata": {
        "id": "AQh__MKuDhX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFtGIdSqbEOZ"
      },
      "outputs": [],
      "source": [
        "datasetConDimensionesReducidas.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RTG4Qt9ccBu"
      },
      "source": [
        "## **4. Clusterización y visualización de *embeddings***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizar gráficas para identificar número óptimo de clústeres:"
      ],
      "metadata": {
        "id": "94TLK7PCDz1Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfTwsNNWcecc"
      },
      "source": [
        "Definir función para **Método del Codo** para calcular número ideal de clústers para los datos cargados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMmtd5NFcdqh"
      },
      "outputs": [],
      "source": [
        "def elbowMethod(df, columnWiEmbeddings, rangoPosibleDeCluster, byRegion=False):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWiEmbeddings].tolist())\n",
        "    # Calcula la inercia para diferentes valores de k (número de clústeres)\n",
        "    # Inicializa una lista vacía para almacenar los valores de inercia calculados para cada número de clústeres\n",
        "    inertia_values = []\n",
        "    # Define un rango de valores de k (número de clústeres) para probar, basándose en el rango proporcionado como argumento\n",
        "    possible_k_values = range(rangoPosibleDeCluster[0], rangoPosibleDeCluster[1]+1)  # Prueba k desde n1 hasta n2 clústeres\n",
        "\n",
        "    # Itera sobre el rango de posibles valores de k\n",
        "    for index, k in enumerate(possible_k_values):\n",
        "        # Inicializa el algoritmo KMeans con el número actual de clústeres (k) y una semilla aleatoria fija\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "        # Entrena el modelo KMeans con los embeddings\n",
        "        kmeans.fit(embeddings)\n",
        "\n",
        "        # Añade la inercia del modelo (la suma de las distancias cuadradas de las muestras a su centro de clúster más cercano) a la lista de valores de inercia\n",
        "        inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "    # Prepara los resultados para ser graficados, conteniendo los valores de k y las inercias correspondientes\n",
        "    resToPlot = [possible_k_values, inertia_values]\n",
        "\n",
        "    # Grafica el método del codo utilizando matplotlib, donde el eje X representa el número de clústeres y el eje Y la inercia\n",
        "    plt.plot(resToPlot[0], resToPlot[1], marker='o')\n",
        "    plt.xlabel('Número de Clústeres (k)')\n",
        "    plt.ylabel('Inercia')\n",
        "    plt.title('Método del Codo para Determinar k')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng9IUzHlguCH"
      },
      "source": [
        "**Ejecutar método del codo** para identificar número deseable de clústers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0pCw4dSgxxh"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Calcular número ideal en un rango de 1 a 20 clústers\n",
        "rangoDeClusters = [1,20]\n",
        "elbowMethod(datasetConDimensionesReducidas, columnaConEmbeddings, rangoDeClusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgGoiC-85QEh"
      },
      "source": [
        "Definir función para **Método de Silueta** para calcular número ideal de clústers para los datos cargados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coX058Qt5Pmm"
      },
      "outputs": [],
      "source": [
        "def silhouetteMethod(df, columnWithEmbeddings, rangeOfClusters):\n",
        "    # Convierte la columna de embeddings del DataFrame a un array de numpy para su procesamiento\n",
        "    embeddings = np.array(df[columnWithEmbeddings].tolist())\n",
        "\n",
        "    # Establece el número de subplots basado en el rango de clústeres a analizar\n",
        "    n_clusters = range(rangeOfClusters[0], rangeOfClusters[1] + 1)\n",
        "    n_rows = len(n_clusters) // 2 + len(n_clusters) % 2\n",
        "    fig, ax = plt.subplots(n_rows, 2, figsize=(16, 32))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "    # Itera sobre el rango especificado de número de clústeres\n",
        "    for i, k in enumerate(n_clusters):\n",
        "        # Crea una instancia de KMeans para el número actual de clústeres\n",
        "        km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
        "\n",
        "        # Calcula la fila y columna para el subplot actual\n",
        "        q, mod = divmod(i, 2)\n",
        "\n",
        "        # Crea una instancia de SilhouetteVisualizer para visualizar el coeficiente de silueta\n",
        "        visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q][mod])\n",
        "\n",
        "        # Ajusta el visualizador con los embeddings\n",
        "        visualizer.fit(embeddings)\n",
        "\n",
        "        # Establece el título del subplot\n",
        "        ax[q][mod].set_title(f'Clusters: {k}')\n",
        "\n",
        "    # Ajusta la disposición de los subplots para evitar solapamientos\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUt22TJUKG1G"
      },
      "outputs": [],
      "source": [
        "# Ejecutar función de método de silueta\n",
        "silhouetteMethod(dfClusters, 'embeddingsReducidos', (2, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCgFS0ucg0n"
      },
      "source": [
        "Definir función de clusterizarización utilizando método **K-Means:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m26wIKEciSI"
      },
      "outputs": [],
      "source": [
        "# Definir función de clusterización con K-means\n",
        "def clusterKmeans(df, optimal_k_value, columnaEmbeddings, byRegion=False, cluster_col_name=None):\n",
        "    embeddings = df[columnaEmbeddings].tolist()\n",
        "    dfW = df.copy() # Crear copia de trabajo de DataFrame\n",
        "\n",
        "    if cluster_col_name is None:\n",
        "      cluster_col_name = \"cluster\"\n",
        "\n",
        "    try:\n",
        "        if byRegion: # Clusterización por región (opcional, no utilizado en metodología final)\n",
        "            # Inicializar nueva columna para alojar etiquetas de clústeres\n",
        "            dfW[cluster_col_name] = None\n",
        "\n",
        "            # Iterar sobre cada región (opcional)\n",
        "            for region, df_region in dfW.groupby('region'):\n",
        "                # Aplicar clusterización de K-means en cada región (opcional)\n",
        "                kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "                cluster_labels = kmeans.fit_predict(df_region[columnaEmbeddings].tolist())\n",
        "\n",
        "                # Añadir prefijo de clúster por región (opcional)\n",
        "                prefixed_cluster_labels = [f\"{region}_{label}\" for label in cluster_labels]\n",
        "\n",
        "                # Asignar etiquetas de clúster por región a DataFrame\n",
        "                dfW.loc[dfW['region'] == region, cluster_col_name] = prefixed_cluster_labels\n",
        "        else:\n",
        "            # Aplicar clusterización por K-means a todo el conjunto de datos importado (versión implementada en metodología final)\n",
        "            kmeans = KMeans(n_clusters=optimal_k_value, random_state=0)\n",
        "            cluster_labels = kmeans.fit_predict(embeddings)\n",
        "            dfW[cluster_col_name] = cluster_labels\n",
        "\n",
        "        return dfW\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar clusters: {e}\")\n",
        "        return pd.DataFrame({0: [\"Error al generar clusters\"]})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Definir número de clústeres a segmentar:"
      ],
      "metadata": {
        "id": "BrwiHdOuEEqi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8e-qbFYhV3a"
      },
      "source": [
        "**Ejecutar clusterización** con número deseado de clúster con método *k-means:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYDZGoBShW-2"
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "\n",
        "# Input para el número de clusters\n",
        "numero_clusters_input = widgets.IntText(\n",
        "    value=7,\n",
        "    description='Núm. Clusters:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para confirmar la selección y ejecutar la segmentación en clusters\n",
        "cluster_button = widgets.Button(\n",
        "    description='Segmentar Clusters',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para ejecutar la segmentación en clusters\n",
        "def segmentar_clusters(b):\n",
        "    global dfClusterizado\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        numeroDeClusters = numero_clusters_input.value\n",
        "        dfClusterizado = clusterKmeans(datasetConDimensionesReducidas, numeroDeClusters, columnaConEmbeddings, byRegion=False)\n",
        "        print(f\"Segmentación en {numeroDeClusters} clusters completada.\")\n",
        "\n",
        "cluster_button.on_click(segmentar_clusters)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(numero_clusters_input, cluster_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previsualizar tabla con clústeres segmentados:"
      ],
      "metadata": {
        "id": "nXOChDeHELzB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSnflYhvvupM"
      },
      "outputs": [],
      "source": [
        "# Previsualizar tabla de registros con sus respectivos clústers asignados\n",
        "dfClusterizado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizar en 3D *embeddings* generados y clústeres:"
      ],
      "metadata": {
        "id": "BBqVmU4CETye"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65amorfRec8J"
      },
      "source": [
        "Definir función para **visualizar relaciones semánticas y clústeres en 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvxpKaLbeltl"
      },
      "outputs": [],
      "source": [
        "def visualize3D(df, columnaEmbeddingsReducidas, columnaTexto, byCategory=False, columnaCluster=None):\n",
        "  if columnaCluster is None:\n",
        "    columnaCluster = \"cluster\"\n",
        "  embeddingWithSelectedDimensions = df[columnaEmbeddingsReducidas].tolist()\n",
        "  dfToPlot = {\n",
        "        \"X\": [x[0] for x in embeddingWithSelectedDimensions],\n",
        "        \"Y\": [y[1] for y in embeddingWithSelectedDimensions],\n",
        "        \"Z\": [z[2] for z in embeddingWithSelectedDimensions],\n",
        "        \"cluster\": df[columnaCluster].tolist(),\n",
        "        \"text\": df[columnaTexto]\n",
        "  }\n",
        "\n",
        "  fig = px.scatter_3d(dfToPlot, x='X', y='Y', z='Z', color='cluster', hover_data=[\"text\"],\n",
        "                         labels={'X': 'Dimensión 1', 'Y': 'Dimensión 2', 'Z': 'Dimensión 3'},\n",
        "                         title=f'Visualización de clústers semánticos',\n",
        "                         color_discrete_sequence=px.colors.sequential.Viridis)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97inR3riC6g"
      },
      "source": [
        "**Ejecutar visualización de clústers 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Indicar columna de texto para etiquetas\n",
        "columnaTextoClusterizado = \"clean_text\"\n",
        "visualize3D(dfClusterizado, columnaConEmbeddings, columnaTextoClusterizado, columnaCluster=\"cluster\")"
      ],
      "metadata": {
        "id": "o6tepsl3FGVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \\*Exportar archivos de datos con *embeddings* generados y clústeres:"
      ],
      "metadata": {
        "id": "iC4hJwr9FOBu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_elu-UcSfhWH"
      },
      "source": [
        "**Exportar archivos de datos (formato CSV y JSON) con clústers calculados:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et8wiYQFiXI1"
      },
      "outputs": [],
      "source": [
        "# Dropdown para seleccionar el formato de exportación\n",
        "format_dropdown = widgets.Dropdown(\n",
        "    options=['csv', 'json'],\n",
        "    value='csv',\n",
        "    description='Formato:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Input de texto para el nombre del archivo\n",
        "file_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe el nombre del archivo',\n",
        "    description='Nombre Archivo:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Botón para exportar el archivo\n",
        "export_button = widgets.Button(\n",
        "    description='Exportar',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Output widget para mostrar mensajes\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para exportar el archivo\n",
        "def export_file(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        file_name = file_name_input.value\n",
        "        file_format = format_dropdown.value\n",
        "        if file_format == 'csv':\n",
        "            dfClusterizado.to_csv(f\"{file_name}.csv\", index=False)\n",
        "            print(f\"Archivo {file_name}.csv exportado exitosamente.\")\n",
        "        elif file_format == 'json':\n",
        "            dfClusterizado.to_json(f\"{file_name}.json\", orient='records', lines=True)\n",
        "            print(f\"Archivo {file_name}.json exportado exitosamente.\")\n",
        "\n",
        "export_button.on_click(export_file)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(format_dropdown, file_name_input, export_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Postprocesar datos para visualización en Cosmograph:"
      ],
      "metadata": {
        "id": "dI8CUFQkI6-H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiiL8gizB73W"
      },
      "source": [
        "Preparar dataset clusterizado para su visualización en **Cosmograph**:\n",
        "\n",
        "- Crear columna **cluster-str** basada en cluster. Cambiar valores a letras en orden alfabético.\n",
        "- Crear nueva columna **x**  a partir del primer valor de reduced_embeddings.\n",
        "- Crear nueva columna **y**  a partir del segundo valor de reduced_embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función para postprocesar los clusters y agregar nuevas columnas\n",
        "def postprocessClusters(dfClusterizado):\n",
        "    # Crear un diccionario para convertir números a letras (A-Z)\n",
        "    number_to_letter = {\n",
        "        0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',\n",
        "        5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
        "        10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O',\n",
        "        15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T'\n",
        "    }\n",
        "\n",
        "    # Crear las nuevas columnas\n",
        "    dfClusterizado['cluster-str'] = dfClusterizado['cluster'].map(number_to_letter)\n",
        "    dfClusterizado['x'] = dfClusterizado['embeddingsReducidos'].apply(lambda value: value[0])\n",
        "    dfClusterizado['y'] = dfClusterizado['embeddingsReducidos'].apply(lambda value: value[1])\n",
        "\n",
        "    # Devolver el nuevo dataframe con las columnas agregadas\n",
        "    global dfFinal\n",
        "    dfFinal = dfClusterizado.copy()\n",
        "\n",
        "# Llamar a la función para procesar el dataframe\n",
        "postprocessClusters(dfClusterizado)\n",
        "\n",
        "# Mostrar las primeras filas del nuevo dataframe\n",
        "dfFinal.head()\n"
      ],
      "metadata": {
        "id": "1QU0YvupHYZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exportar archivo de datos (formato CSV) procesado para su compatibilidad con la aplicación [Cosmograph](https://cosmograph.app):**"
      ],
      "metadata": {
        "id": "DoONbWbzt9KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfFinal.to_csv(f\"{project_name.value}_cosmograph.csv\", index=False)"
      ],
      "metadata": {
        "id": "rmAT8dp_ICsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4OQBbdRsRRd"
      },
      "source": [
        "## **5. Referencias:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvDL8Tfgr_6s"
      },
      "source": [
        "* Bird, Steven, Edward Loper & Ewan Klein (2009). Natural Language Processing with Python.  O'Reilly Media Inc.\n",
        "* McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426. https://arxiv.org/abs/1802.03426\n",
        "* Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E., & others. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\n",
        "* Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (arXiv:1908.10084). arXiv. http://arxiv.org/abs/1908.10084\n",
        "* Rousseeuw, P. (1987). Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics. 20: 53–65. doi:10.1016/0377-0427(87)90125-7.\n",
        "* Spärck-Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28(1), 11-21. https://www.staff.city.ac.uk/~sbrp622/idfpapers/ksj_orig.pdf\n",
        "* Thorndike, R. (1953). Who Belongs in the Family?. Psychometrika. 18 (4): 267–276. doi:10.1007/BF02289263. S2CID 120467216.\n",
        "* Wang, L., Yang, N., Huang, X., Yang, L., Majumder, R., & Wei, F. (2024). Multilingual E5 Text Embeddings: A Technical Report. arXiv preprint arXiv:2402.05672. Recuperado de https://arxiv.org/abs/2402.05672\n",
        "\n",
        "*Programación asistida ocasionalmente con herramientas de IA Generativa: ChatGPT, Phind, Google Gemini y Perplexity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASBLPGoSNBqe"
      },
      "source": [
        "## **6. Créditos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdAyvK0mOkwZ"
      },
      "source": [
        "**Realizado por el equipo de Signa_Lab ITESO:**\n",
        "\n",
        "- **Programación de cuadernos de código (Python)**:\n",
        "Javier de la Torre Silva, José Luis Almendarez González y Diego Arredondo Ortiz\n",
        "\n",
        "- **Supervisión del desarrollo tecnológico y documentación:**\n",
        "Diego Arredondo Ortiz\n",
        "\n",
        "- **Equipo de Coordinación Signa_Lab ITESO:**\n",
        "Paloma López Portillo Vázquez, Víctor Hugo Ábrego Molina y Eduardo G. de Quevedo Sánchez\n",
        "\n",
        "Mayo, 2024. Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO)\n",
        "Tlaquepaque, Jalisco, México.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "-VJl3gf3A1RM",
        "ugJGAWJg2aq1",
        "qbw5IfbABQxb",
        "cjDYVGEsBr4q",
        "HY2TjRZHCFP8",
        "aMLTMg7DCah9",
        "8-fP-hdfUCdx",
        "bshcLIAYDXiq",
        "AQh__MKuDhX9",
        "94TLK7PCDz1Z",
        "BrwiHdOuEEqi",
        "nXOChDeHELzB",
        "BBqVmU4CETye",
        "iC4hJwr9FOBu",
        "dI8CUFQkI6-H"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}