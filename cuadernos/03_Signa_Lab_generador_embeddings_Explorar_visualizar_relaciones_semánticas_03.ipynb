{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Signa_Lab ITESO:** Generador de *Embbeddings*\n",
        "\n",
        "## **Cuaderno 03:** Exploración y visualización de *embeddings*, consultas y relaciones semánticas (*ngramas*).\n",
        "Cuaderno de código para explorar y visualizar relaciones semánticas codificadas en *embeddings* (vectores) y clústeres previamente procesados (ver  [cuaderno 01](https://github.com/signalab/generador-embeddings/blob/main/cuadernos/01_Signa_Lab_generador_embeddings_Depuraci%C3%B3n_importar_limpiar_depurar_texto_01.ipynb) y [cuaderno 02](https://github.com/signalab/generador-embeddings/blob/main/cuadernos/02_Signa_Lab_generador_embeddings_Generar_procesar_reducir_clusterizar_embeddings_01.ipynb)), con ayuda de modelos de lenguaje de la librería [sentence-transformers](https://www.sbert.net/), alojados en repositorios de [HuggingFace](https://huggingface.co/sentence-transformers), así como desde la aplicación de técnicas establecidas de procesamiento de lenguaje natural (PNL), como TF-IDF y ngramas.\n",
        "\n",
        "**\\***Los grupos de celdas marcadas con **asterisco requieren información** antes de seguir adelante."
      ],
      "metadata": {
        "id": "Fp7hsz51O4As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importar librerías, archivos de datos y modelos de lenguaje"
      ],
      "metadata": {
        "id": "BB3YQRFXHgz1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9cxszdGFQyM"
      },
      "source": [
        "### Instalar e importar librerías:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4NdF2f5Z-hM"
      },
      "source": [
        "**Instalar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La8LHgKEZn1Q"
      },
      "outputs": [],
      "source": [
        "# Instalar librerías de Python necesarias\n",
        "\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install plotly\n",
        "# !pip install umap-learn\n",
        "!pip install sentence_transformers\n",
        "\n",
        "!pip install matplotlib\n",
        "# !pip install yellowbrick\n",
        "!pip install networkx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HNO8OtcDfAr"
      },
      "source": [
        "**Importar librerías:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evuyVCCMaQEd"
      },
      "outputs": [],
      "source": [
        "# Importar librerías de Python necesarias\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "# from sklearn.decomposition import PCA\n",
        "# import umap\n",
        "# from sklearn.manifold import TSNE\n",
        "import operator\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "# from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Indicar rutas de archivos de datos a importar y nombre de proyecto:"
      ],
      "metadata": {
        "id": "srKDCQg4H6cc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQks_5TDaqXa"
      },
      "source": [
        "**Importar (y concatenar, en caso de ser múltiples) archivos de datos** con embeddings y clústeres procesados (en formato JSON o CSV):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir función para cargar archivos a partir de la extensión en su ruta indicada\n",
        "def load_file(path):\n",
        "    if path.endswith('.csv'):\n",
        "        return pd.read_csv(path)\n",
        "    elif path.endswith('.xlsx'):\n",
        "        return pd.read_excel(path)\n",
        "    elif path.endswith('.json'):\n",
        "        return pd.read_json(path)\n",
        "    else:\n",
        "        raise ValueError(\"Formato no compatible. Por favor carga solo archivos .csv or .xlsx.\")\n",
        "\n",
        "# Inicializar lista para alojar todas las rutas y una variable para el DataFrame final, accesible globalmente\n",
        "file_paths = []\n",
        "dfs = []\n",
        "df = None  # DataFrame global\n",
        "\n",
        "# Definir función para añadir un nuevo campo de texto (input) para añadir una ruta de archivo adicional\n",
        "def add_file_input(b=None):\n",
        "    path_input = widgets.Text(value='', placeholder='Escribe la ruta del archivo', description=f'Archivo {len(file_paths) + 1}:')\n",
        "    file_paths.append(path_input)\n",
        "    update_ui()\n",
        "\n",
        "# Definir función para eliminar el último campo de texto (input) para ruta de archivo\n",
        "def remove_file_input(b=None):\n",
        "    if file_paths:\n",
        "        file_paths.pop()\n",
        "        update_ui()\n",
        "\n",
        "# Definir función para procesar y cargar todos los archivos\n",
        "def process_files(b):\n",
        "    global dfs, df\n",
        "    dfs = []  # Vaciar DataFrames\n",
        "\n",
        "    for path_input in file_paths:\n",
        "        path = path_input.value\n",
        "        try:\n",
        "            temp_df = load_file(path)\n",
        "            temp_df['filename'] = path  # Add a column with the filename\n",
        "            dfs.append(temp_df)\n",
        "            print(f\"Nombre de archivo: {path}\")\n",
        "            print(f\"Filas/Columnas (shape): {temp_df.shape}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error al cargar el archivo {path}: {e}\")\n",
        "            return\n",
        "\n",
        "    if dfs:\n",
        "        df = pd.concat(dfs, ignore_index=True)  # Concatenate all DataFrames\n",
        "        print(\"\\n¡Se cargaron todos los archivos!\")\n",
        "        print(f\"Filas/Columnas (shape) de DataFrame creado: {df.shape}\")\n",
        "\n",
        "# Campo de texto (input) para indicar nombre del proyecto (para integrarse en nombres de archivos a exportar)\n",
        "project_name = widgets.Text(value='', placeholder='Escribe el nombre del proyecto (corto y sin espacios)', description='Nombre del proyecto:')\n",
        "\n",
        "# Botones para añadir y eliminar archivos\n",
        "add_button = widgets.Button(description=\"Añadir archivo\",button_style='')\n",
        "remove_button = widgets.Button(description=\"Eliminar archivo\", button_style='warning')\n",
        "load_button = widgets.Button(description=\"Cargar archivos\", button_style='primary')\n",
        "\n",
        "add_button.on_click(add_file_input)\n",
        "remove_button.on_click(remove_file_input)\n",
        "load_button.on_click(process_files)\n",
        "\n",
        "# Definir función para actualizar UI\n",
        "def update_ui():\n",
        "    clear_output()\n",
        "    display(project_name)\n",
        "    for path_input in file_paths:\n",
        "        display(path_input)\n",
        "    display(widgets.HBox([add_button, remove_button]))\n",
        "    display(load_button)\n",
        "\n",
        "# Inicializar UI con un campo de texto (input) para ruta de archivo\n",
        "add_file_input()\n"
      ],
      "metadata": {
        "id": "rdY3i3i1Ie0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previsualizar datos importados:"
      ],
      "metadata": {
        "id": "7pIw0eYqMeQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer una copia de trabajo del DataFrame global con datos importados\n",
        "dfClusterizado = df\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "ExD2C-HIIxnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Previsualizar tabla** con todos los registros importados:"
      ],
      "metadata": {
        "id": "xhhozeo5MiKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsualizar dataframe con CSVs importados\n",
        "display(dfClusterizado)"
      ],
      "metadata": {
        "id": "kQ4ccVMKMkbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exportar copia en CSV con registros importados (o concatenados):**"
      ],
      "metadata": {
        "id": "Irlr-2a_MoaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar archivo CSV con tabla de registros importados (y concatenados, en el caso de múltiples archivos)\n",
        "dfClusterizado.to_csv(f\"{project_name.value}_registros-clusterizados-importados.csv\")\n",
        "dfClusterizado.to_json(f\"{project_name.value}_registros-clusterizados-importados.json\")"
      ],
      "metadata": {
        "id": "Pn4eWR63MqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Indicar e importar modelo de lenguaje:"
      ],
      "metadata": {
        "id": "_N4tfykWU_u9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzYy63BFwuFk"
      },
      "source": [
        "**Importar modelo de lenguaje para búsqueda semántica:**\n",
        "\n",
        "\\* Para ejecutar consultas de búsqueda semántica, se debe cargar el mismo modelo de lenguaje que el utilizado para generar *embeddings* en los datos importados. Por default, se cargará el modelo de software libre [intfloat/multilingual-e5-large-instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct) (Wang et al, 2024), con la librería de aprendizaje profundo [sentence-transformers](https://www.sbert.net/) (Reimers & Gurevych, 2019), pero pueden utilizarse otros del [repositorio en Hugging Face](https://huggingface.co/sentence-transformers) de dicha librería o cargados localmente."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Opciones de modelos predefinidos\n",
        "model_options = [\n",
        "    \"intfloat/multilingual-e5-large-instruct\",\n",
        "    \"all-mpnet-base-v2\",\n",
        "    \"all-MiniLM-L12-v2\",\n",
        "    \"paraphrase-multilingual-mpnet-base-v2\",\n",
        "    \"facebook-dpr-ctx_encoder-multiset-base\",\n",
        "    \"otro (ruta de otro modelo en la nube o ruta local)\"\n",
        "]\n",
        "\n",
        "# Crear dropdown para seleccionar modelo\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=model_options,\n",
        "    value=model_options[0],  # valor por defecto\n",
        "    description=\"Modelos sugeridos:\",\n",
        ")\n",
        "\n",
        "# Crear campo de texto para ruta personalizada (solo se mostrará si se elige 'otro')\n",
        "model_path_text = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe la ruta a otro modelo...',\n",
        "    description='Ruta manual:',\n",
        "    disabled=True  # Deshabilitado inicialmente\n",
        ")\n",
        "\n",
        "# Botón para cargar el modelo\n",
        "load_button = widgets.Button(description=\"Cargar Modelo\")\n",
        "output = widgets.Output()\n",
        "\n",
        "# Función para habilitar/deshabilitar el campo de texto según la selección\n",
        "def on_model_select(change):\n",
        "    if change['new'] == \"otro (ruta de otro modelo en la nube o ruta local)\":\n",
        "        model_path_text.disabled = False  # Habilitar el input de ruta personalizada\n",
        "    else:\n",
        "        model_path_text.disabled = True  # Deshabilitar si se elige un modelo predefinido\n",
        "\n",
        "# Función para cargar el modelo\n",
        "def load_model(b):\n",
        "    global embedder  # Hacer que embedder sea una variable global\n",
        "    with output:\n",
        "        clear_output()\n",
        "\n",
        "        # Verificar si el modelo seleccionado es 'otro'\n",
        "        if model_dropdown.value == \"otro (ruta de otro modelo en la nube o ruta local)\":\n",
        "            model = model_path_text.value  # Tomar la ruta escrita por el usuario\n",
        "        else:\n",
        "            model = model_dropdown.value  # Tomar el modelo predefinido\n",
        "\n",
        "        # Cargar el modelo usando SentenceTransformer\n",
        "        try:\n",
        "            embedder = SentenceTransformer(model)\n",
        "            print(f\"Modelo '{model}' cargado con éxito.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar el modelo: {e}\")\n",
        "\n",
        "# Conectar la selección del dropdown a la función\n",
        "model_dropdown.observe(on_model_select, names='value')\n",
        "\n",
        "# Conectar el botón de cargar a la función de carga de modelo\n",
        "load_button.on_click(load_model)\n",
        "\n",
        "# Mostrar widgets\n",
        "display(model_dropdown, model_path_text, load_button, output)\n"
      ],
      "metadata": {
        "id": "EJQj3wzQpZBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjCpUBmP6Htk"
      },
      "source": [
        "## 2. Visualización de clústers y búsqueda semántica"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizar *embeddings* y clústeres:"
      ],
      "metadata": {
        "id": "dmjH9PX2GqVV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65amorfRec8J"
      },
      "source": [
        "Definir función para **visualizar relaciones semánticas y clústeres en 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvxpKaLbeltl"
      },
      "outputs": [],
      "source": [
        "def visualize3D(df, columnaEmbeddingsReducidas, columnaTexto, byCategory=False, columnaCluster=None):\n",
        "  if columnaCluster is None:\n",
        "    columnaCluster = \"cluster\"\n",
        "  embeddingWithSelectedDimensions = df[columnaEmbeddingsReducidas].tolist()\n",
        "  dfToPlot = {\n",
        "        \"X\": [x[0] for x in embeddingWithSelectedDimensions],\n",
        "        \"Y\": [y[1] for y in embeddingWithSelectedDimensions],\n",
        "        \"Z\": [z[2] for z in embeddingWithSelectedDimensions],\n",
        "        \"cluster\": df[columnaCluster].tolist(),\n",
        "        \"text\": df[columnaTexto]\n",
        "  }\n",
        "\n",
        "  fig = px.scatter_3d(dfToPlot, x='X', y='Y', z='Z', color='cluster', hover_data=[\"text\"],\n",
        "                         labels={'X': 'Dimensión 1', 'Y': 'Dimensión 2', 'Z': 'Dimensión 3'},\n",
        "                         title=f'Visualización de clústers semánticos',\n",
        "                         color_discrete_sequence=px.colors.sequential.Viridis)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97inR3riC6g"
      },
      "source": [
        "**Ejecutar visualización de clústers 3D:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtVgG0BRiFSl",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Indicar nombre de columna con embeddings reducidos\n",
        "columnaConEmbeddings = \"embeddingsReducidos\"\n",
        "# Indicar columna de texto para etiquetas\n",
        "columnaTextoClusterizado = \"clean_text\"\n",
        "visualize3D(dfClusterizado, columnaConEmbeddings, columnaTextoClusterizado, columnaCluster=\"cluster\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuC-tFGkdm8p"
      },
      "source": [
        "### *Búsqueda semántica general y por clústeres:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx15BlfVBSSt"
      },
      "source": [
        "**Identificar clústers más grandes en la muestra del tema** (mayor frecuencia de preguntas por similitud semántica):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar y enlistar los clústeres con mayor cantidad de registros (de mayor a menor)\n",
        "cluster_freq = dfClusterizado['cluster'].value_counts(ascending=False).head(20)\n",
        "\n",
        "# Crear una lista con los clústeres en orden descendente de cantidad de registros\n",
        "cluster_list = cluster_freq.index.tolist()\n",
        "\n",
        "# Imprimir los clústeres en el formato solicitado\n",
        "for i, cluster in enumerate(cluster_list):\n",
        "    print(f\"cluster[{i}] - valor del {i+1}º clúster con más registros ({cluster_freq[cluster]} registros)\")\n"
      ],
      "metadata": {
        "id": "GccmdD5WKyFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de producto punto\n",
        "def dotProduct(embedding1, embedding2):\n",
        "    result = sum(e1 * e2 for e1, e2 in zip(embedding1, embedding2))\n",
        "    return result\n",
        "\n",
        "# Definir la función de búsqueda semántica\n",
        "def searchIntFloat(model, task, query, df, colText, colEmbedding, cluster=None):\n",
        "    dfW = df.copy()\n",
        "    if cluster is not None and cluster != 'Todos':\n",
        "        dfW = dfW[dfW[\"cluster\"] == cluster]\n",
        "\n",
        "    def get_detailed_instruct(task_description: str, query: str) -> str:\n",
        "        return f'Instruct: {task_description}\\nQuery: {query}'\n",
        "\n",
        "    # Preparar la consulta\n",
        "    queries = [\n",
        "        get_detailed_instruct(task, query)\n",
        "    ]\n",
        "\n",
        "    # Obtener el embedding de la consulta\n",
        "    queryEmbeddings = model.encode(queries, convert_to_tensor=True, normalize_embeddings=True).tolist()[0]\n",
        "\n",
        "    listOfTweetsAndSimilarity = []\n",
        "    # Calcular la similitud con cada registro del DataFrame\n",
        "    for index, row in dfW.iterrows():\n",
        "        embeddingRow = row[colEmbedding]\n",
        "        if type(embeddingRow) == str:\n",
        "          # embeddingRow = [float(x) for x in embeddingRow.split(\", \")]\n",
        "          embeddinStr = dfClusterizado[\"Embedding\"][index].replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
        "          embeddingRow = [float(x) for x in embeddinStr]\n",
        "        similarity = dotProduct(queryEmbeddings, embeddingRow)\n",
        "        listOfTweetsAndSimilarity.append(similarity)\n",
        "\n",
        "    # Agregar la columna de similitud al DataFrame original filtrado\n",
        "    dfW['Similitud'] = listOfTweetsAndSimilarity\n",
        "\n",
        "    # Reordenar las columnas para que \"Similitud\" sea la primera\n",
        "    cols = ['Similitud'] + [col for col in dfW.columns if col != 'Similitud']\n",
        "    dfW = dfW[cols]\n",
        "\n",
        "    # Ordenar los resultados por similitud en orden descendente\n",
        "    dfW = dfW.sort_values(by=\"Similitud\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return dfW\n",
        "\n",
        "\n",
        "# Definir la función para ejecutar la búsqueda basada en los widgets\n",
        "def ejecutar_busqueda(b):\n",
        "    # Limpiar el output antes de imprimir nuevos resultados\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Leer los valores de los widgets\n",
        "        task = task_widget.value\n",
        "        query = query_widget.value\n",
        "        colText = colText_widget.value\n",
        "        colEmbedding = colEmbedding_widget.value\n",
        "        cluster = cluster_dropdown.value\n",
        "\n",
        "        # Ejecutar la búsqueda\n",
        "        global dfResultados\n",
        "        dfResultados = searchIntFloat(embedder, task, query, dfClusterizado, colText, colEmbedding, cluster)\n",
        "\n",
        "        # Obtener los primeros 100 valores de las columnas 'id', 'Similitud', y el texto de 'colText'\n",
        "        top_100_rows = dfResultados[['id', 'Similitud', colText]].head(100)\n",
        "\n",
        "        # Imprimir los valores en formato legible en la consola\n",
        "        for idx, row in top_100_rows.iterrows():\n",
        "            print(f\"ID: {row['id']}, Similitud: {row['Similitud']:.4f}, Texto: {row[colText]}\")\n",
        "\n",
        "        # También se puede mostrar dfResultados.head() si es necesario para depuración\n",
        "        # display(dfResultados.head())\n",
        "\n",
        "# Crear widgets con mayor espacio para los textos\n",
        "task_widget = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Explica el contexto de la tarea',\n",
        "    description='Tarea:',\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "query_widget = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Escribe tu consulta',\n",
        "    description='Consulta:',\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "colText_widget = widgets.Text(\n",
        "    value='sem_text',\n",
        "    placeholder='Nombre de columna de texto',\n",
        "    description='Columna texto:',\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "colEmbedding_widget = widgets.Text(\n",
        "    value='Embedding',\n",
        "    placeholder='Nombre de columna de embeddings',\n",
        "    description='Columna embeddings:',\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "cluster_dropdown = widgets.Dropdown(\n",
        "    options=['Todos'] + cluster_list,  # Añadir 'Todos' para búsqueda en todo el dataframe\n",
        "    value='Todos',\n",
        "    description='Cluster:',\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "execute_button = widgets.Button(description=\"Ejecutar búsqueda con palabras clave o una frase\")\n",
        "execute_button.on_click(ejecutar_busqueda)\n",
        "\n",
        "# Output para mostrar los resultados\n",
        "output = widgets.Output()\n",
        "\n",
        "# Mostrar widgets\n",
        "display(task_widget, query_widget, colText_widget, colEmbedding_widget, cluster_dropdown, execute_button, output)\n",
        "\n",
        "# Inicializar dfResultados como una variable global vacía\n",
        "dfResultados = pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "xSmA2Lqo1XbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar Pandas para truncar valores largos en las columnas\n",
        "pd.set_option('display.max_colwidth', 50)  # Máximo de 50 caracteres por celda antes de truncar\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "dfResultados.head()\n"
      ],
      "metadata": {
        "id": "BreQig_tN14R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Visualización de resultados de búsqueda semántica (mapa de árbol):"
      ],
      "metadata": {
        "id": "va6m4iLAACKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable global para almacenar el umbral de similitud\n",
        "similarityThreshold = 0.85\n",
        "\n",
        "# Función que se ejecuta cuando se presiona el botón \"Ajustar\"\n",
        "def ajustar_threshold(b):\n",
        "    global similarityThreshold\n",
        "    try:\n",
        "        # Leer el valor del input de texto y convertirlo a float\n",
        "        new_threshold = float(threshold_input.value)\n",
        "        if 0.0 <= new_threshold <= 1.0:\n",
        "            similarityThreshold = new_threshold\n",
        "            print(f\"Umbral de similitud ajustado a: {similarityThreshold}\")\n",
        "\n",
        "            # Filtrar el DataFrame dfResultados y contar los registros\n",
        "            filtered_df = dfResultados[dfResultados['Similitud'] >= similarityThreshold]\n",
        "            record_count = len(filtered_df)\n",
        "            print(f\"Número de registros con similitud >= {similarityThreshold}: {record_count}\")\n",
        "        else:\n",
        "            print(\"Por favor, ingrese un valor entre 0.0 y 1.0.\")\n",
        "    except ValueError:\n",
        "        print(\"Por favor, ingrese un número válido.\")\n",
        "\n",
        "# Crear un input de texto para el umbral de similitud\n",
        "threshold_input = widgets.Text(\n",
        "    value='0.85',\n",
        "    description='Umbral:',\n",
        "    placeholder='Ingrese un valor entre 0.0 y 1.0'\n",
        ")\n",
        "\n",
        "# Crear un botón para ajustar el umbral\n",
        "adjust_button = widgets.Button(\n",
        "    description='Filtrar'\n",
        ")\n",
        "\n",
        "# Vincular el botón al ajuste del umbral\n",
        "adjust_button.on_click(ajustar_threshold)\n",
        "\n",
        "# Mostrar el input de texto y el botón\n",
        "display(threshold_input, adjust_button)\n"
      ],
      "metadata": {
        "id": "1YbXYWod8__S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar el treemap basado en la similitud\n",
        "def generar_treemap(df, similarity_threshold):\n",
        "    # Filtrar filas donde la columna 'title' y 'source/name' estén vacías o tengan valores nulos\n",
        "    df_filtrado = df.dropna(subset=['videoTitle', 'channelTitle']).copy()\n",
        "\n",
        "    # Filtrar los registros que tienen una similitud mayor o igual a similarity_threshold\n",
        "    df_filtrado = df_filtrado[df_filtrado['Similitud'] >= similarity_threshold]\n",
        "\n",
        "    # Asegurarse de que la columna 'cluster' sea tratada como cadena\n",
        "    df_filtrado['cluster'] = df_filtrado['cluster'].astype(str)\n",
        "\n",
        "    if df_filtrado.empty:\n",
        "        print(f\"No hay datos con similitud >= {similarity_threshold}\")\n",
        "        return\n",
        "\n",
        "    # Crear el treemap utilizando 'source/name' y 'cluster' para las categorías y 'Similitud' para el tamaño\n",
        "    fig = px.treemap(\n",
        "        df_filtrado,\n",
        "        path=['cluster', 'channelTitle', 'videoTitle'],  # Definir la estructura jerárquica\n",
        "        values='Similitud',  # Utilizar la columna 'Similitud' para el tamaño de los rectángulos\n",
        "        title=f'Treemap de Canal y Clústeres por Similitud (Umbral: {similarity_threshold})'\n",
        "    )\n",
        "\n",
        "    # Ajustar el formato y tamaño de las etiquetas\n",
        "    fig.update_traces(\n",
        "        texttemplate=\"%{label}\",  # Mostrar etiquetas de texto con los nombres\n",
        "        textfont=dict(size=18, color='white')  # Tamaño y color de la fuente de las etiquetas\n",
        "    )\n",
        "\n",
        "    # Ajustar los márgenes de la visualización\n",
        "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
        "\n",
        "    # Mostrar el treemap interactivo\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "j1NCVEk76Vvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generar_treemap(dfResultados, similarityThreshold)"
      ],
      "metadata": {
        "id": "C41zL-bO7kZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLdKJ8CFCnGR"
      },
      "source": [
        "## 3. Análisis semántico por frecuencia de términos (TF-IDF) y de relaciones entre palabras (ngramas)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis semántico general (dataset completo):"
      ],
      "metadata": {
        "id": "cPeNlhVPOiIZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC76hXp4cHki"
      },
      "source": [
        "Definir función para identificar **términos más frecuentes por método TF-IDF con toda la muestra:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0jMWalncWS2"
      },
      "outputs": [],
      "source": [
        "# Definir función para calcular términos frecuentes por método TF-IDF para muestra completa\n",
        "def generateTfidfForCompleteSample(df, columnaPreguntas, n=20):\n",
        "  vectorizador_tfidf = TfidfVectorizer()\n",
        "  tfidf_matriz = vectorizador_tfidf.fit_transform(df[columnaPreguntas])\n",
        "  terminos = vectorizador_tfidf.get_feature_names_out()\n",
        "  tfidf_promedio = tfidf_matriz.mean(axis=0).tolist()[0]\n",
        "  tfidf_terminos = [(termino, tfidf) for termino, tfidf in zip(terminos, tfidf_promedio)]\n",
        "  tfidf_terminos_importantes = sorted(tfidf_terminos, key=lambda x: x[1], reverse=True)[:n]\n",
        "  return tfidf_terminos_importantes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHnCIT3W1rUr"
      },
      "source": [
        "Definir función para identificar **relaciones entre pares de palabras (bigramas) más frecuentes:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2OoKbly-7Xb"
      },
      "outputs": [],
      "source": [
        "# Definir función para calcular bigramas indicando un clúster específico u omitirlo para aplicarse con la muestra completa\n",
        "def calculate_bigrams(df, nCluster=None):\n",
        "    # Inicializar una lista para alojar todas las palabras en columna 'pregunta'\n",
        "    all_words = []\n",
        "\n",
        "    if nCluster is not None:\n",
        "      dfW = df[df[\"cluster\"] == nCluster]\n",
        "      df = pd.DataFrame(dfW[\"sem_text\"])\n",
        "    else:\n",
        "      df = pd.DataFrame(df[\"sem_text\"])\n",
        "\n",
        "    # Correr filtro por stopwords\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "    for pregunta in df['sem_text']:\n",
        "        # Tokenizar textos de columna pregunta text por palabra\n",
        "        tokens = word_tokenize(pregunta, language='spanish')\n",
        "        # Filtrar stopwords de tokens\n",
        "        filtered_words = [word for word in tokens if word.lower() not in stop_words]\n",
        "        all_words.extend(filtered_words)\n",
        "\n",
        "    # Configurar identificador de bigramas\n",
        "    bigram_measures = BigramAssocMeasures()\n",
        "    bigram_finder = BigramCollocationFinder.from_words(all_words)\n",
        "\n",
        "    # Calcular peso de bigramas utilizando frecuencia\n",
        "    bigrams = bigram_finder.score_ngrams(bigram_measures.raw_freq)\n",
        "\n",
        "    # Convertir bigramas calculados y su frecuencia en dataFrame\n",
        "    bigrams_df = pd.DataFrame([(src, tgt, weight) for ((src, tgt), weight) in bigrams],\n",
        "                              columns=['source', 'target', 'weight'])\n",
        "\n",
        "    bigrams_df = bigrams_df.sort_values(by='weight', ascending=False)  # Ordenar bigramas por frecuencia\n",
        "\n",
        "    return bigrams_df  # Regresar dataFrame con lista bigramas ordenados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKfJBTfV34dX"
      },
      "source": [
        "Definir función para identificar **relaciones entre secuencias de 3 palabras (trigramas) más frecuentes:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1siK1aD5CPZQ"
      },
      "outputs": [],
      "source": [
        "# Definir función para calcular trigramas indicando un clúster específico u omitirlo para aplicarse con la muestra completa\n",
        "def calculate_trigrams(df, nCluster=None):\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "    all_words = []\n",
        "\n",
        "    if nCluster is not None:\n",
        "      dfW = df[df[\"cluster\"] == nCluster]\n",
        "      df = pd.DataFrame(dfW[\"sem_text\"])\n",
        "    else:\n",
        "      df = pd.DataFrame(df[\"sem_text\"])\n",
        "\n",
        "    for pregunta in df['sem_text']:  # Adjust this to match your column name\n",
        "        tokens = word_tokenize(pregunta)\n",
        "        filtered_words = [word for word in tokens if word not in stop_words]\n",
        "        all_words.extend(filtered_words)\n",
        "\n",
        "    bigram_measures = BigramAssocMeasures()\n",
        "    trigram_finder = TrigramCollocationFinder.from_words(all_words)\n",
        "\n",
        "    trigrams = trigram_finder.score_ngrams(bigram_measures.raw_freq)\n",
        "\n",
        "    trigrams_df = pd.DataFrame([(src, mid, tgt, weight) for ((src, mid, tgt), weight) in trigrams],\n",
        "                               columns=['source', 'middle', 'target', 'weight'])\n",
        "\n",
        "    trigrams_df = trigrams_df.sort_values(by='weight', ascending=False)  # Ordenar bigramas por frecuencia\n",
        "\n",
        "    return trigrams_df   # Regresar dataFrame con lista bigramas ordenados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvEfaFCb2U6p"
      },
      "source": [
        "Ejecutar función para identificar **términos más frecuentes por método TF-IDF con toda la muestra:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0hLUIHWdeuL"
      },
      "outputs": [],
      "source": [
        "# Indicar número de términos más frecuentes a enlistar por método TF-IDF\n",
        "nPalabrasFrecuentesDatasetCompleto = 20\n",
        "tfidfDatasetCompleto = generateTfidfForCompleteSample(dfClusterizado, \"sem_text\", nPalabrasFrecuentesDatasetCompleto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUyxOplpdxPL"
      },
      "outputs": [],
      "source": [
        "# Enlistar términos más frecuentes en muestra completa por método TF-IDF\n",
        "tfidfDatasetCompleto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIphLfwtGaN5"
      },
      "outputs": [],
      "source": [
        "df_tfidfDatasetCompleto = pd.DataFrame(tfidfDatasetCompleto, columns=[\"términos\",\"frecuencias\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3RtSfP4GBCS"
      },
      "outputs": [],
      "source": [
        "top_tfidf_muestra = df_tfidfDatasetCompleto.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(top_tfidf_muestra['términos'], top_tfidf_muestra['frecuencias'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('TF-IDF')\n",
        "plt.title(f'Top 20 de Términos en Muestra Completa del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-nEZCUue-mU"
      },
      "source": [
        "Ejecutar función para identificar **relaciones entre pares de palabras (bigramas) más frecuentes en toda la muestra:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Uj6gpLOQ255"
      },
      "outputs": [],
      "source": [
        "# Ejecutar cálculo de bigramas\n",
        "bigrama_muestra = calculate_bigrams(dfClusterizado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nby7J_bU3QMA"
      },
      "outputs": [],
      "source": [
        "bigrama_muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKtzDKpp27lu"
      },
      "outputs": [],
      "source": [
        "top_bigrams_muestra = bigrama_muestra.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(top_bigrams_muestra['source'] + ' ' + top_bigrams_muestra['target'], top_bigrams_muestra['weight'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('Bigrama')\n",
        "plt.title(f'Top 20 Bigramas en Muestra Completa del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install networkx\n"
      ],
      "metadata": {
        "id": "LmBY58UJ_liO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import networkx as nx\n",
        "# import plotly.graph_objects as go\n",
        "\n",
        "def visualize_bigrams(bigrams_df, top_n=100):\n",
        "    # Crear un grafo dirigido\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Añadir nodos y bordes al grafo con pesos\n",
        "    for _, row in bigrams_df.iterrows():\n",
        "        G.add_edge(row['source'], row['target'], weight=row['weight'])\n",
        "\n",
        "    # Calcular el grado ponderado de cada nodo\n",
        "    weighted_degree = dict(G.degree(weight='weight'))\n",
        "\n",
        "    # Ordenar nodos por grado ponderado y seleccionar los top_n\n",
        "    top_nodes = sorted(weighted_degree.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    top_nodes = set(node for node, _ in top_nodes)\n",
        "\n",
        "    # Crear un subgrafo con los nodos seleccionados\n",
        "    H = G.subgraph(top_nodes).copy()\n",
        "\n",
        "    # Obtener posiciones de los nodos usando el layout de Fruchterman-Reingold\n",
        "    pos = nx.spring_layout(H, seed=42)\n",
        "\n",
        "    # Obtener los bordes y los pesos para visualización\n",
        "    edge_trace = go.Scatter(\n",
        "        x=[],\n",
        "        y=[],\n",
        "        line=dict(width=0.5, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "\n",
        "    for edge in H.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_trace['x'] += (x0, x1, None)\n",
        "        edge_trace['y'] += (y0, y1, None)\n",
        "\n",
        "    # Obtener los nodos para visualización\n",
        "    node_trace = go.Scatter(\n",
        "        x=[],\n",
        "        y=[],\n",
        "        text=[],\n",
        "        mode='markers+text',\n",
        "        textposition='top center',\n",
        "        marker=dict(\n",
        "            size=[],  # Dejar espacio para ajustar tamaño de nodos\n",
        "            color='#1f78b4',\n",
        "            line=dict(width=2, color='rgb(0,0,0)')\n",
        "        )\n",
        "    )\n",
        "\n",
        "    for node in H.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_trace['x'] += (x,)\n",
        "        node_trace['y'] += (y,)\n",
        "        node_trace['text'] += (node,)\n",
        "        # Escalar el tamaño de los nodos por el grado ponderado\n",
        "        node_trace['marker']['size'] += (weighted_degree[node] * 1000,)\n",
        "\n",
        "    # Crear la visualización interactiva con Plotly\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=0)\n",
        "                    ))\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "vyRa5TuK_plb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar grafo con bigramas de top 100 nodos por grado con pesos\n",
        "bigrams_df = calculate_bigrams(dfClusterizado)  # Calcular bigramas\n",
        "visualize_bigrams(bigrams_df)  # Visualizar bigramas"
      ],
      "metadata": {
        "id": "O3PQhOe6GXin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo4rnf6Se7NV"
      },
      "source": [
        "Ejecutar función para identificar **relaciones entre secuencias de 3 palabras (trigramas) más frecuentes:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd0Lho6UQvee"
      },
      "outputs": [],
      "source": [
        "# Ejecutar cálculo de trigramas\n",
        "trigrama_muestra = calculate_trigrams(dfClusterizado)\n",
        "trigrama_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0anMPoYZnzMf"
      },
      "source": [
        "**Visualizar trigramas de toda la muestra**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtEEESY8n1j-"
      },
      "outputs": [],
      "source": [
        "top_trigrams_muestra = trigrama_muestra.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(top_trigrams_muestra['source'] + ' ' + top_trigrams_muestra['middle'] + ' ' + top_trigrams_muestra['target'], top_trigrams_muestra['weight'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('Trigrama')\n",
        "plt.title(f'Top 20 Trigramas en Muestra Completa del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx_GVV2lDjKh"
      },
      "source": [
        "### *Análisis semántico por clústeres:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropdown basado en lista ordenada de top clusters, con opción de elegir manualmente algún y abrir espacio para escribirlo manualmente en un input de texto, como con modelos. Una sola función de clúster ajustable, no triplicar."
      ],
      "metadata": {
        "id": "WZEIZcL4RLrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKWeZGmUBx5Q"
      },
      "source": [
        "Definir función para identificar **términos más frecuentes por método TF-IDF por clúster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2lB9VRzWgc3"
      },
      "outputs": [],
      "source": [
        "# Definir función para calcular términos frecuentes por método TF-IDF por clúster\n",
        "def funcion_tfidf_cluster(dfClusterizado, n=20, agrupar_por_region=False, n_cluster=None):\n",
        "    # Inicializar el vectorizador TF-IDF\n",
        "    vectorizador_tfidf = TfidfVectorizer()\n",
        "\n",
        "    # Calcular las características TF-IDF por cluster\n",
        "    tfidf_por_cluster = {}\n",
        "\n",
        "    if agrupar_por_region:\n",
        "        for region, df_region in dfClusterizado.groupby('region'):\n",
        "            clusters = df_region['cluster'].unique()\n",
        "            for cluster in clusters:\n",
        "                if n_cluster is not None and cluster != n_cluster:\n",
        "                    continue\n",
        "                preguntas_cluster = df_region[df_region['cluster'] == cluster]['sem_text'].dropna()\n",
        "                tfidf_matriz = vectorizador_tfidf.fit_transform(preguntas_cluster)\n",
        "                terminos = vectorizador_tfidf.get_feature_names_out()\n",
        "                tfidf_promedio = tfidf_matriz.mean(axis=0).tolist()[0]\n",
        "                tfidf_terminos = [(termino, tfidf) for termino, tfidf in zip(terminos, tfidf_promedio)]\n",
        "                tfidf_terminos_importantes = sorted(tfidf_terminos, key=lambda x: x[1], reverse=True)[:n]\n",
        "                if region not in tfidf_por_cluster:\n",
        "                    tfidf_por_cluster[region] = {}\n",
        "                tfidf_por_cluster[region][cluster] = tfidf_terminos_importantes\n",
        "    else:\n",
        "        clusters = dfClusterizado['cluster'].unique()\n",
        "        for cluster in clusters:\n",
        "            if n_cluster is not None and cluster != n_cluster:\n",
        "                continue\n",
        "            preguntas_cluster = dfClusterizado[dfClusterizado['cluster'] == cluster]['sem_text'].dropna()\n",
        "            tfidf_matriz = vectorizador_tfidf.fit_transform(preguntas_cluster)\n",
        "            terminos = vectorizador_tfidf.get_feature_names_out()\n",
        "            tfidf_promedio = tfidf_matriz.mean(axis=0).tolist()[0]\n",
        "            tfidf_terminos = [(termino, tfidf) for termino, tfidf in zip(terminos, tfidf_promedio)]\n",
        "            tfidf_terminos_importantes = sorted(tfidf_terminos, key=lambda x: x[1], reverse=True)[:n]\n",
        "            tfidf_por_cluster[cluster] = tfidf_terminos_importantes\n",
        "\n",
        "    # Devolver los términos TF-IDF más prominentes por cluster y región si se agrupó por región, de lo contrario, solo por cluster\n",
        "    return tfidf_por_cluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que esta es tu lista de clústers en orden descendente\n",
        "# (Ejemplo, reemplaza esto con tu lista real de clústers)\n",
        "# clusters = ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Cluster5']\n",
        "\n",
        "# Variable global para almacenar el clúster seleccionado\n",
        "filteredCluster = cluster_list[0]  # Valor inicial\n",
        "\n",
        "# Función que se ejecuta cuando se selecciona un clúster del menú desplegable\n",
        "def on_cluster_change(change):\n",
        "    global filteredCluster\n",
        "    filteredCluster = change['new']\n",
        "    print(f\"Clúster seleccionado: {filteredCluster}\")\n",
        "\n",
        "# Crear un menú desplegable con los clústers\n",
        "cluster_dropdown = widgets.Dropdown(\n",
        "    options=cluster_list,\n",
        "    value=cluster_list[0],  # Valor inicial\n",
        "    description='Elegir clúster:',\n",
        "    style={'description_width': 'initial'}  # Opcional: ajustar el ancho de la descripción\n",
        ")\n",
        "\n",
        "# Vincular el menú desplegable al método on_cluster_change\n",
        "cluster_dropdown.observe(on_cluster_change, names='value')\n",
        "\n",
        "# Mostrar el menú desplegable\n",
        "display(cluster_dropdown)"
      ],
      "metadata": {
        "id": "ed3GJ-JSDxcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filteredCluster)"
      ],
      "metadata": {
        "id": "HMiWdKXoEGjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D14uCPOp79SW"
      },
      "source": [
        "**Calcular términos más frecuentes por método TF-IDF para 1er clúster:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwY0noeTXUFh"
      },
      "outputs": [],
      "source": [
        "# Indicar número de clúster y cantidad de términos a enlistar con mayor puntuación tras el análisis TF-IDF\n",
        "# cluster_tfid_1 = 0\n",
        "n_terminos = 20\n",
        "\n",
        "# tfidf_por_cluster_region = funcion_tfidf(dfClusterizado, n=3, agrupar_por_region=True, n_cluster=cluster_tfid)\n",
        "tfidf_por_cluster = funcion_tfidf_cluster(dfClusterizado, n=n_terminos, agrupar_por_region=False, n_cluster=filteredCluster)\n",
        "\n",
        "# Enlistar términos con mayor frecuencia en clúster calculados por análisis TF-IDF\n",
        "tfidf_por_cluster = tfidf_por_cluster[filteredCluster]\n",
        "tfidf_por_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_msc18zwUem"
      },
      "outputs": [],
      "source": [
        "# tfidf_por_cluster_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDnxYwYlWhzH"
      },
      "outputs": [],
      "source": [
        "# # Enlistar términos con mayor frecuencia en clúster calculados por análisis TF-IDF\n",
        "# tfidf_por_cluster_1 = tfidf_por_cluster_1[filteredCluster]\n",
        "# tfidf_por_cluster_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-5-tKd3jhKw"
      },
      "outputs": [],
      "source": [
        "df_tfidf_cluster = pd.DataFrame(tfidf_por_cluster, columns=[\"términos\", \"frecuencias\"])\n",
        "df_tfidf_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtA60Za6jrYl"
      },
      "outputs": [],
      "source": [
        "top_tfidf_cluster = df_tfidf_cluster.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.barh(df_tfidf_cluster['términos'], df_tfidf_cluster['frecuencias'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('TF-IDF')\n",
        "plt.title(f'Top 20 de Términos en Clúster {filteredCluster} en Muestra del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLIW2j_H62LY"
      },
      "source": [
        "**Calcular bigrama para 1er clúster:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtoUWKTufHPJ"
      },
      "outputs": [],
      "source": [
        "# Indicar número de clúster con mayor cantidad de preguntas\n",
        "# n_cluster_1 = cluster_1\n",
        "bigrama_cluster = calculate_bigrams(dfClusterizado, filteredCluster)\n",
        "bigrama_cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKmF9ImjmLAX"
      },
      "source": [
        "**Visualizar bigrama de 1er cluster** con mayor cantidad de preguntas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adUgYAHNmogC"
      },
      "outputs": [],
      "source": [
        "top_bigrams_cluster = bigrama_cluster.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(top_bigrams_cluster['source'] + ' ' + top_bigrams_cluster['target'], top_bigrams_cluster['weight'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('Bigrama')\n",
        "plt.title(f'Top 20 Bigramas en Clúster {filteredCluster} en Muestra del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_bigrams(bigrama_cluster)  # Visualizar bigramas"
      ],
      "metadata": {
        "id": "s0cEcPoVGSDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMGmiiF6fQKX"
      },
      "source": [
        "**Calcular trigrama para 1er clúster:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpg75mcXfSQn"
      },
      "outputs": [],
      "source": [
        "trigrama_cluster = calculate_trigrams(dfClusterizado, filteredCluster)\n",
        "trigrama_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GdaP1hl7mMA"
      },
      "outputs": [],
      "source": [
        "top_trigrams_cluster = trigrama_cluster.head(20)\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(top_trigrams_cluster['source'] + ' ' + top_trigrams_cluster['middle'] + ' ' + top_trigrams_cluster['target'], top_trigrams_cluster['weight'], color='skyblue')\n",
        "plt.xlabel('Frecuencia')\n",
        "plt.ylabel('Trigrama')\n",
        "plt.title(f'Top 20 Trigramas en Clúster (número {filteredCluster}) en Muestra del Tema {project_name.value}')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Extracción manual de registros por ID (opcional)"
      ],
      "metadata": {
        "id": "irIAW6t1IQtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Previsualizar filas a extraer manualmente por ID:"
      ],
      "metadata": {
        "id": "sSlTjcg4IXOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roblZE1gJnj4"
      },
      "outputs": [],
      "source": [
        "# Previsualizar registro por ID\n",
        "dfClusterizado[dfClusterizado[\"id\"]== 1006310]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqlLWo4MJ-On"
      },
      "outputs": [],
      "source": [
        "# Previsualizar registro por ID\n",
        "dfClusterizado[dfClusterizado[\"id\"]== 1005157]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Generar tabla con registros seleccionados por ID:"
      ],
      "metadata": {
        "id": "z6KFUPoMIqSS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsAnWkkh-Om3"
      },
      "outputs": [],
      "source": [
        "# Definir función que recibe una lista de IDs para crear DataFrame con los registros a extraer\n",
        "def seleccionar_preguntas_por_ids(dfClusters, dfSelectedQuestions, selectedIDs):\n",
        "    # Crear una copia del DataFrame original para evitar modificaciones directas\n",
        "    dfClusters_copia = dfClusters.copy()\n",
        "\n",
        "    # Filtrar los registros seleccionados basados la lista de IDs proporcionados\n",
        "    df_seleccionados = dfClusters_copia[dfClusters_copia[\"id\"].isin(selectedIDs)]\n",
        "\n",
        "    # Eliminar de la copia del DataFrame global los registros seleccionadoss\n",
        "    dfClusters_copia = dfClusters_copia[~dfClusters_copia[\"id\"].isin(selectedIDs)]\n",
        "\n",
        "    # Si dfSelectedQuestions está vacío, inicializarlo con las columnas de dfClusters\n",
        "    if dfSelectedQuestions.empty:\n",
        "        dfSelectedQuestions = pd.DataFrame(columns=dfClusters.columns)\n",
        "\n",
        "    # Obtener el índice para las nuevas filas en el DataFrame de registros seleccionados\n",
        "    nuevo_indice = len(dfSelectedQuestions)\n",
        "\n",
        "    # Agregar las filas seleccionadas al DataFrame de registros seleccionados\n",
        "    for _, row in df_seleccionados.iterrows():\n",
        "        dfSelectedQuestions.loc[nuevo_indice] = row\n",
        "        nuevo_indice += 1\n",
        "\n",
        "    return dfClusters_copia, dfSelectedQuestions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUsszYf9EcOm"
      },
      "source": [
        "**Enlistar IDs de resgistros seleccionados** para extraer en una tabla nueva:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selectedIDs = [1006310, 1005157, 1003136]  # Lista de IDs seleccionados\n",
        "\n",
        "dfClusters = dfClusterizado.copy()\n",
        "dfSelectedQuestions = pd.DataFrame(columns=dfClusters.columns)  # DataFrame vacío para registros seleccionados\n",
        "\n",
        "dfClusters_actualizado, dfSelectedQuestions_actualizado = seleccionar_preguntas_por_ids(dfClusters, dfSelectedQuestions, selectedIDs)"
      ],
      "metadata": {
        "id": "ed7FC1qrJvgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfClusters_actualizado.shape"
      ],
      "metadata": {
        "id": "urvyWAgkK9pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSelectedQuestions_actualizado"
      ],
      "metadata": {
        "id": "MWXcPE4VLAFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1MYRQAA-Om4"
      },
      "outputs": [],
      "source": [
        "#Verificar eliminacion por id\n",
        "id_por_verficar = '1000103'\n",
        "dfClusters_actualizado[dfClusters_actualizado['id'] == id_por_verficar]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIR3r6knwQcT"
      },
      "outputs": [],
      "source": [
        "# Exportar archivo de datos (en formato CSV) con registros seleccionados\n",
        "dfSelectedQuestions_actualizado.to_csv(f\"{project_name.value}RegistrosSeleccionados.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntgZwEcDwUev"
      },
      "outputs": [],
      "source": [
        "# Exportar archivo de datos (en formato CSV) con el resto de registros no seleccionados\n",
        "dfClusters_actualizado.to_csv(f\"{project_name.value}RegistrosSinSeleccionados.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqcDpQGLTe2a"
      },
      "source": [
        "## 5. Referencias:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l-uV6I9Tgsp"
      },
      "source": [
        "* Bird, Steven, Edward Loper & Ewan Klein (2009). Natural Language Processing with Python.  O'Reilly Media Inc.\n",
        "* McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426. https://arxiv.org/abs/1802.03426\n",
        "* Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E., & others. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\n",
        "* Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks (arXiv:1908.10084). arXiv. http://arxiv.org/abs/1908.10084\n",
        "* Rousseeuw, P. (1987). Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics. 20: 53–65. doi:10.1016/0377-0427(87)90125-7.\n",
        "* Spärck-Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28(1), 11-21. https://www.staff.city.ac.uk/~sbrp622/idfpapers/ksj_orig.pdf\n",
        "* Thorndike, R. (1953). Who Belongs in the Family?. Psychometrika. 18 (4): 267–276. doi:10.1007/BF02289263. S2CID 120467216.\n",
        "* Wang, L., Yang, N., Huang, X., Yang, L., Majumder, R., & Wei, F. (2024). Multilingual E5 Text Embeddings: A Technical Report. arXiv preprint arXiv:2402.05672. Recuperado de https://arxiv.org/abs/2402.05672\n",
        "\n",
        "*Programación asistida ocasionalmente con herramientas de IA Generativa: ChatGPT, Phind, Google Gemini y Perplexity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Créditos"
      ],
      "metadata": {
        "id": "mSSpSLNlM9Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizado por el equipo de Signa_Lab ITESO:**\n",
        "\n",
        "- **Programación de cuadernos de código (Python)**:\n",
        "Javier de la Torre Silva, José Luis Almendarez González y Diego Arredondo Ortiz\n",
        "\n",
        "- **Supervisión del desarrollo tecnológico y documentación:**\n",
        "Diego Arredondo Ortiz\n",
        "\n",
        "- **Equipo de Coordinación Signa_Lab ITESO:**\n",
        "Paloma López Portillo Vázquez, Víctor Hugo Ábrego Molina y Eduardo G. de Quevedo Sánchez\n",
        "\n",
        "Mayo, 2024. Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO)\n",
        "Tlaquepaque, Jalisco, México.\n"
      ],
      "metadata": {
        "id": "lgBlWd9tNBnG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k9cxszdGFQyM",
        "srKDCQg4H6cc",
        "7pIw0eYqMeQK",
        "_N4tfykWU_u9",
        "BjCpUBmP6Htk",
        "cPeNlhVPOiIZ",
        "kx_GVV2lDjKh",
        "sSlTjcg4IXOL",
        "z6KFUPoMIqSS"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}